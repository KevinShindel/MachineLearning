
## Overfitting in ANN

> - Overfits the training data and performs poorly on the test data.
> - When the model has very high accuracy when predicting against the training dataset, but low accuracy an independent dataset
> - ANNs has the tendency to overfit when models are complex and deep

## Overfitting: Solutions

> - Simpler models (reduce layers and nodes in a layer)
> - Smaller epochs and batch size
> - Increase data size and variety
> - Regularization
> - Dropout

## Regularization in ANN

> -  Controls overfitting during model training
> - An adjustment to the model parameters to prevent them overfitting
> - Reduce variance in the model
> - Multiple options: L1, L2, ElasticNet, etc.


## Regularization experiment

```python
accuracy_measures = {}

regularizer_list = ['l1','l2','l1_l2']
for regularizer in regularizer_list:
    
    model_config = base_model_config()
    X,Y = get_data()
    
    model_config["REGULARIZER"] = regularizer
    model_config["EPOCHS"]=25
    model_name = "Regularizer-" + regularizer
    history=create_and_run_model(model_config,X,Y, model_name)
    
    #Switch to validation accuracy
    accuracy_measures[model_name] = history.history["val_accuracy"]
```

## TODO: Regularization experiment results


## Dropout

> - Dropping out nodes randomly during forward propagation
> - A given percent of nodes are dropped randomly
> - Choose values that provide similar accuracy for both training and test data

## Dropout experiment

```python
accuracy_measures = {}

dropout_list = [0.0, 0.1, 0.2, 0.5]
for dropout in dropout_list:
    model_config = base_model_config()
    X, Y = get_data()

    model_config["DROPOUT_RATE"] = dropout
    model_config["EPOCHS"] = 25
    model_name = "Dropout-" + str(dropout)
    history = create_and_run_model(model_config, X, Y, model_name)

    # Using validation accuracy
    accuracy_measures[model_name] = history.history["val_accuracy"]
```

## TODO: Dropout experiment results