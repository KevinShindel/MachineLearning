{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Goal: The goal of this competition is to use various factors to predict obesity risk in individuals, which is related to cardiovascular disease.\n",
    "### Evaluation: Submissions are evaluated using the **accuracy** score."
   ],
   "id": "c3a0f44e99730c4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# My place is 2524/3587 (Top 70%)\n",
    "# Public Score: 0.89920\n",
    "# Private score: 0.89432"
   ],
   "id": "37a1b37529f7f68f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Submission File\n",
    "For each id row in the test set, you must predict the class value of the target, NObeyesdad. The file should contain a header and have the following format:\n",
    "\n",
    "| id    | NObeyesdad    |\n",
    "|-------|---------------|\n",
    "| 20757 | Normal_Weight |\n",
    "| 20758 | Normal_Weight |\n",
    "| 20759 | Normal_Weight |\n",
    "| 20760 | Normal_Weight |"
   ],
   "id": "ea30bd668b6b0247"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- id: unique identifier for each individual\n",
    "- Gender: male / female\n",
    "- Age: age in years\n",
    "- Height: height in meters\n",
    "- Weight: weight in kilograms\n",
    "- family_history_with_overweight: yes / no\n",
    "- FAVC: frequently consumes high caloric food: yes / no\n",
    "- FCVC: frequency of consumption of vegetables: 1 to 3 (1 - never, 2 - sometimes, 3 - always)\n",
    "- NCP: number of main meals: 1 to 3 (1 - one meal, 2 - two meals, 3 - three meals)\n",
    "- CAEC: consumption of food between meals: 1 to 4 (1 - never, 2 - sometimes, 3 - frequently, 4 - always)\n",
    "- SMOKE: yes / no\n",
    "- CH2O: daily water consumption: 1 to 3 (1 - less than 1 liter, 2 - 1 to 2 liters, 3 - more than 2 liters)\n",
    "- SCC: calorie consumption monitoring: yes / no\n",
    "- FAF: physical activity frequency: 1 to 3 (1 - never, 2 - sometimes, 3 - always)\n",
    "- TUE: time using technology devices: 1 to 4 (1 - less than 1 hour, 2 - 1 to 2 hours, 3 - 2 to 4 hours, 4 - more than 4 hours)\n",
    "- CALC: consumption of alcohol: yes / no\n",
    "- MTRANS: means of transportation used most often:\n",
    "    - 1 - walking\n",
    "    - 2 - bike\n",
    "    - 3 - motorbike\n",
    "    - 4 - public transportation\n",
    "    - 5 - car\n",
    "- NObeyesdad: the obesity level of the individual, which is the target variable to predict. The possible values are:\n",
    "    - Insufficient_Weight\n",
    "    - Normal_Weight\n",
    "    - Overweight_Level_I\n",
    "    - Overweight_Level_II\n",
    "    - Obesity_Type_I\n",
    "    - Obesity_Type_II\n",
    "    - Obesity_Type_III"
   ],
   "id": "b2edf5ca73c923d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ],
   "id": "cfba6cf4ba69c47a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_path = '/kaggle/input/playground-series-s4e2/test.csv'\n",
    "train_path = '/kaggle/input/playground-series-s4e2/train.csv'\n",
    "submission_path = '/kaggle/working/submission.csv'\n",
    "target_column = 'NObeyesdad'"
   ],
   "id": "1050cef8d839f83e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_data = pd.read_csv(test_path)\n",
    "train_data = pd.read_csv(train_path)\n",
    "submission_data = pd.read_csv(submission_path)"
   ],
   "id": "c0c395fd8f063683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data.head()",
   "id": "73993cb9fcff1d2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data.describe()",
   "id": "b02f95caa13c50be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data.info()",
   "id": "b37ee5e8638ddb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = train_data.drop(columns=[target_column])\n",
    "y = train_data[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ],
   "id": "d0a5dcee59b7b137",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Custom transformer to create new features based on existing ones.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Create new features based on existing ones.\"\"\"\n",
    "        X['is_kid'] = (X['Age'] <= 12).astype(int)\n",
    "        X['is_teen'] = ((X['Age'] > 12) & (X['Age'] <= 19)).astype(int)\n",
    "        X['is_young_adult'] = ((X['Age'] > 19) & (X['Age'] <= 39)).astype(int)\n",
    "        X['is_adult'] = ((X['Age'] > 39) & (X['Age'] <= 59)).astype(int)\n",
    "        X['is_senior'] = (X['Age'] > 59).astype(int)\n",
    "        return X\n"
   ],
   "id": "b8e70f4780fc446b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[object]).columns.tolist()\n",
    "drop_cols = ['Age', 'id']  # keep id and target variable for correlation analysis\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "        ('drop', 'drop', drop_cols)  # drop columns\n",
    "    ],\n",
    "    remainder='drop', n_jobs=-1\n",
    ")"
   ],
   "id": "456ef8a9aaf02da5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target_encoder = OrdinalEncoder()\n",
    "\n",
    "y_test = pd.Series(target_encoder.fit_transform(y_test.values.reshape(-1, 1)).ravel(), name=target_column)\n",
    "y_train = pd.Series(target_encoder.transform(y_train.values.reshape(-1, 1)).ravel(), name=target_column)"
   ],
   "id": "770074262669c909",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a pipeline with custom transformer\n",
    "transformer = Pipeline(steps=[\n",
    "    ('feature_engineering', FeatureTransformer()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ],
   "id": "1fbba23de4e104a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)",
   "id": "6f881126fbe33edf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# estimator = HistGradientBoostingClassifier(max_iter=280, learning_rate=0.1, max_depth=5)\n",
    "# pipeline = make_pipeline(transformer, estimator)\n",
    "#\n",
    "# # let's tune model using RandomSearchCV\n",
    "# param_grid = {\n",
    "#     'histgradientboostingclassifier__max_iter': [100, 200, 300, 500],\n",
    "#     'histgradientboostingclassifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "#     'histgradientboostingclassifier__max_depth': [None, 3, 5, 7, 10],\n",
    "#     'histgradientboostingclassifier__min_samples_leaf': [10, 20, 30, 50],\n",
    "#     'histgradientboostingclassifier__l2_regularization': [0.0, 0.1, 1.0],\n",
    "#     'histgradientboostingclassifier__max_bins': [32, 64, 128, 255],\n",
    "#     'histgradientboostingclassifier__early_stopping': [True, False]\n",
    "# }\n",
    "#\n",
    "# search = RandomizedSearchCV(pipeline,\n",
    "#                             param_grid,\n",
    "#                             n_iter=20,\n",
    "#                             cv=cv,\n",
    "#                             scoring='accuracy',\n",
    "#                             n_jobs=-1,\n",
    "#                             verbose=1,\n",
    "#                             return_train_score=False)\n",
    "#\n",
    "#\n",
    "# search.fit(X_train, y_train)"
   ],
   "id": "8fcb919fa3f61907",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# best_model = search.best_estimator_\n",
    "# best_score = -search.best_score_"
   ],
   "id": "d8a466cb03f351d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scores = cross_val_score(best_model, X_test, y_test, scoring='accuracy', cv=cv)\n",
    "# mean_score = scores.mean()\n",
    "# r2_score = best_model.score(X_test, y_test)\n",
    "#\n",
    "# print(f'Best Parameters: {search.best_params_}')\n",
    "# print(f'Best Cross-Validation Score: {best_score}') # -0.9052752982543538\n",
    "# print(f'Mean Accuracy: {mean_score}') # 0.8906467748249316\n",
    "# print(f'R2 Score: {r2_score}') # 0.910645472061657"
   ],
   "id": "39a0a451a699996f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_params = {'histgradientboostingclassifier__min_samples_leaf': 50, 'histgradientboostingclassifier__max_iter': 100, 'histgradientboostingclassifier__max_depth': 5, 'histgradientboostingclassifier__max_bins': 255, 'histgradientboostingclassifier__learning_rate': 0.1, 'histgradientboostingclassifier__l2_regularization': 0.1, 'histgradientboostingclassifier__early_stopping': False}\n",
    "\n",
    "pipeline = make_pipeline(transformer, HistGradientBoostingClassifier(**{k.split('__')[1]: v for k, v in best_params.items()}))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "best_model = pipeline"
   ],
   "id": "161f023d3b70c263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# let's predict on test data\n",
    "y_test_pred = best_model.predict(test_data)"
   ],
   "id": "2932c47fff255417",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save predictions to submission file\n",
    "_id = test_data['id']\n",
    "submission_df = pd.DataFrame({'id': _id, target_column: y_test_pred})\n",
    "# let's revert target encoding\n",
    "submission_df[target_column] = target_encoder.inverse_transform(\n",
    "    y_test_pred.reshape(-1, 1)\n",
    ").ravel()\n",
    "submission_df.to_csv(submission_path, index=False)"
   ],
   "id": "5d0df83183985ce3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
