{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The Titanic Challenge\n",
    "\n",
    "Current Score: 0.77990\n",
    "Rank: 3218/13637 - TOP 25%  (% 23.6)"
   ],
   "id": "5924bb98c296462b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ],
   "id": "b7388e83cb22ec0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load data\n",
    "train_path = '/kaggle/input/titanic/train.csv'\n",
    "test_path = '/kaggle/input/titanic/test.csv'\n",
    "output_path = '/kaggle/working/submission.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path) # training data\n",
    "test_data = pd.read_csv(test_path) # test data\n",
    "test_pass_id = test_data['PassengerId'] # save PassengerId for submission"
   ],
   "id": "22c311d4da207d04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def feature_engineering(_train_data, _test_data):\n",
    "    # Example feature engineering: creating a family size feature\n",
    "    for dataset in [_train_data, _test_data]:\n",
    "\n",
    "        # Create the variable “FamilySize” by combining the variables “SibSp” and “Parch”.\n",
    "        dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "        # Map ‘Embarqued’ to Embarqued_code{1,2,3}. reserve the zero for NaN.\n",
    "        dataset.loc[dataset['Embarked'].isna(), 'Embarked'] = 'S'  # (Encyclopedia titanica)\n",
    "        dataset['Embarked_code'] = dataset['Embarked'].map({'C': 1, 'Q': 2, 'S': 3}).astype(int)\n",
    "\n",
    "        # Group the duplicated Ticket values and count the number of people that traveled together including friends, maids, and nannies, and create the variable “Companions”.\n",
    "        dataset['Companions'] = dataset['Ticket'].duplicated(keep=False).astype(int) * dataset.groupby('Ticket')['Ticket'].transform(\n",
    "            'count') - 1\n",
    "        dataset.loc[dataset['Companions'] == -1, 'Companions'] = 0\n",
    "\n",
    "        # Create the variable “Title” by extracting the title from the variable “Name”.\n",
    "        def get_title(name):\n",
    "            title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "            # If the title exists, extract and return it.\n",
    "            if title_search:\n",
    "                return title_search.group(1)\n",
    "            return \"\"\n",
    "\n",
    "        dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "        # Clean the variable Title.\n",
    "        dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col',\n",
    "                                           'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'noble')\n",
    "        dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "        dataset['Title'] = dataset['Title'].replace('Ms', 'Mrs')\n",
    "        dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "        # Divide Fare in 10 levels\n",
    "        n = 10\n",
    "        dataset['Fare_level'] = pd.cut(dataset['Fare'], n, labels=np.arange(1, n + 1))\n",
    "\n",
    "        # get the last cabin if exists\n",
    "        dataset['Last_cabin'] = dataset['Cabin'].apply(lambda x: str(x).split()[-1] if pd.notnull(x) else 'N')\n",
    "        # get the Cabin_label of the last cabin\n",
    "        pattern = r'([A-Za-z])'\n",
    "        dataset['Cabin_label'] = dataset['Last_cabin'].apply(lambda x: re.search(pattern, str(x)).group(1) if x != 'N' else 'N')\n",
    "        # Get the number of the last cabin if exists\n",
    "        pattern = r'(\\d+)'\n",
    "        dataset['Cabin_number'] = dataset['Last_cabin'].apply(lambda x: re.search(pattern, str(x)) if x != 'N' else -1)\n",
    "        # Get the number of distinct cabins reserved by the passenger.\n",
    "        dataset['Cabin_count'] = dataset['Cabin'].apply(lambda x: len(str(x).split()) if pd.notnull(x) else 0)\n",
    "        # drop not used columns and columns with NaN values.\n",
    "        dataset.drop(columns=['Cabin', 'Last_cabin', 'Cabin_number'], inplace=True)\n",
    "\n",
    "        # Mapping Age\n",
    "        # fill the missing age with mean\n",
    "        dataset['Age'].fillna(dataset['Age'].mean(), inplace=True)\n",
    "        # Create Age_group feature\n",
    "        dataset.loc[dataset['Age'] <= 13, 'Age_group'] = 0  # kids\n",
    "        dataset.loc[(dataset['Age'] > 13) & (dataset['Age'] <= 30), 'Age_group'] = 1  # young\n",
    "        dataset.loc[(dataset['Age'] > 30) & (dataset['Age'] <= 45), 'Age_group'] = 2  # mature1\n",
    "        dataset.loc[(dataset['Age'] > 45) & (dataset['Age'] <= 60), 'Age_group'] = 3  # old\n",
    "        dataset.loc[(dataset['Age'] > 60) & (dataset['Age'] <= 100), 'Age_group'] = 4  # very old\n",
    "\n",
    "        dataset.drop(columns=['PassengerId', 'Age', 'Embarked', 'Ticket', 'Name'], inplace=True)\n",
    "\n",
    "    return _train_data, _test_data"
   ],
   "id": "e6e4737690e3fc24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_data, test_data = feature_engineering(train_data, test_data)",
   "id": "f1fb4530b6911cf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X, y = train_data.drop('Survived', axis=1), train_data['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ],
   "id": "409287ec1bf34adc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ],
   "id": "d20109dddebe39dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_params = {\n",
    "        'n_estimators': 315,\n",
    "        'max_depth': 14,\n",
    "        'min_samples_split': 12,\n",
    "        'min_samples_leaf': 2,\n",
    "        'max_features': 'sqrt',\n",
    "        'criterion': 'gini',\n",
    "        'bootstrap': True,\n",
    "        'class_weight': None,\n",
    "    }\n",
    "estimator = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "pipeline = make_pipeline(preprocessor, estimator)\n",
    "pipeline.fit(X_train, y_train)"
   ],
   "id": "a2c7ac26b682c14d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "model_score = accuracy_score(y_test, y_pred)"
   ],
   "id": "b9c71ceede871169"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('Model Accuracy: {:.2f}%'.format(model_score * 100))\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "print('Cross-Validation Accuracy: {:.2f}% (+/- {:.2f}%)'.format(\n",
    "    cv_scores.mean() * 100, cv_scores.std() * 100))"
   ],
   "id": "3d380f26c07d0ef0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# let's predict on the test set\n",
    "pass_id = test_pass_id\n",
    "y_rest_predict = pipeline.predict(test_data)"
   ],
   "id": "361a3efd991a0243"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save Submission\n",
    "output = pd.DataFrame({'PassengerId': pass_id, 'Survived': y_rest_predict})\n",
    "output.to_csv(output_path, index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ],
   "id": "dda32ccbed8e5106"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
