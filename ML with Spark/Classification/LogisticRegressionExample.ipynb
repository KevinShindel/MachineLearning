{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import necessary libraries",
   "id": "c7e57ab18be026ef"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-10T17:41:14.611223400Z",
     "start_time": "2026-01-10T17:41:14.591120500Z"
    }
   },
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Spark Session",
   "id": "9ac0c804549f66b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T17:22:39.054025100Z",
     "start_time": "2026-01-10T17:22:38.997738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_spark():\n",
    "    \"\"\" Create a SparkSession object. \"\"\"\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"TestSuite\") \\\n",
    "        .config(key='spark.sql.shuffle.partitions', value='4') \\\n",
    "        .config(key='spark.default.parallelism', value='4') \\\n",
    "        .config(key='spark.sql.session.timeZone', value='UTC') \\\n",
    "        .config(key='spark.ui.enabled', value='false') \\\n",
    "        .config(key='spark.app.id', value='Test') \\\n",
    "        .config(key='spark.driver.host', value='localhost') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    return spark"
   ],
   "id": "f85b20148d65eb9e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T17:22:47.909570100Z",
     "start_time": "2026-01-10T17:22:39.056024900Z"
    }
   },
   "cell_type": "code",
   "source": "spark = create_spark()",
   "id": "1b997b4d888b7e2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Hepatitis Dataset",
   "id": "9867cb8ef77c38a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T17:41:18.098452100Z",
     "start_time": "2026-01-10T17:41:17.892435900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_to_data = '../../dataset/hcvdata.csv'\n",
    "hepatit_spark_df = spark.read.csv(path_to_data, header=True, inferSchema=True)"
   ],
   "id": "64edfbcfa13d6f18",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "8c8510e8e987d42a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T17:41:18.726891800Z",
     "start_time": "2026-01-10T17:41:18.564542600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numeric_cols = ['ALT', 'ALB', 'ALP', 'CHOL', 'PROT']\n",
    "\n",
    "\n",
    "for c in numeric_cols:\n",
    "    hepatit_spark_df = hepatit_spark_df.withColumn(\n",
    "        c,\n",
    "        F.when(F.col(c) == \"NA\", None)\n",
    "        .otherwise(F.col(c).cast(\"double\"))\n",
    "    )\n",
    "\n",
    "hepatit_spark_df = hepatit_spark_df.fillna(0.0, subset=numeric_cols)"
   ],
   "id": "3ded9c9a90625a6e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T17:41:24.257358600Z",
     "start_time": "2026-01-10T17:41:19.040553300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define stages for the pipeline\n",
    "# 1. Index the target variable\n",
    "label_indexer = StringIndexer(inputCol='Category', outputCol='label')\n",
    "\n",
    "# 2. Index and One-Hot Encode 'Sex'\n",
    "sex_indexer = StringIndexer(inputCol='Sex', outputCol='Sex_index')\n",
    "sex_encoder = OneHotEncoder(inputCols=['Sex_index'], outputCols=['Sex_vec'])\n",
    "\n",
    "# 3. Assemble features\n",
    "features = ['Age', 'Sex_vec', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "\n",
    "# 4. Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label', maxIter=100)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[label_indexer,\n",
    "                            sex_indexer,\n",
    "                            sex_encoder,\n",
    "                            assembler,\n",
    "                            lr])\n",
    "\n",
    "# Split data into training and test sets\n",
    "train, test = hepatit_spark_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline_model = pipeline.fit(train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline_model.transform(test)"
   ],
   "id": "80786ad322f61fc6",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation using MulticlassClassificationEvaluator",
   "id": "a782694c9cff175c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T17:41:25.307843Z",
     "start_time": "2026-01-10T17:41:24.260882200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = {\n",
    "    \"accuracy\": MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
    "    \"precision\": MulticlassClassificationEvaluator(metricName=\"weightedPrecision\"),\n",
    "    \"recall\": MulticlassClassificationEvaluator(metricName=\"weightedRecall\"),\n",
    "    \"f1\": MulticlassClassificationEvaluator(metricName=\"f1\"),\n",
    "}\n",
    "\n",
    "for name, evaluator in metrics.items():\n",
    "    # evaluator.setLabelCol(\"label\").setPredictionCol(\"prediction\") # in case custom columns are used\n",
    "    print(name, evaluator.evaluate(y_pred))\n"
   ],
   "id": "602fbec844c03e75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9132653061224489\n",
      "precision 0.9067840732784341\n",
      "recall 0.913265306122449\n",
      "f1 0.9055118300621843\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T17:26:55.689583Z",
     "start_time": "2026-01-10T17:26:55.535655100Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Evaluation using MulticlassMetrics",
   "id": "224fd95fdb07a548"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: something is wrong with this part ( seems in local env )\n",
    "# pl = y_pred.select(\"prediction\", \"label\").rdd.map(lambda r: (float(r.prediction), float(r.label)))\n",
    "# metric = MulticlassMetrics(prediction_and_labels)\n",
    "#\n",
    "# print('Accuracy: ', metric.accuracy)\n",
    "# print('Precision: ', metric.precision(1.0))\n",
    "# print('Recall: ', metric.recall(1.0))\n",
    "# print('F1 Score: ', metric.fMeasure(1.0))"
   ],
   "id": "826573e68ee47b16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: 1. Use CrossValidator for hyperparameter tuning",
   "id": "b6bed3309e267bd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
