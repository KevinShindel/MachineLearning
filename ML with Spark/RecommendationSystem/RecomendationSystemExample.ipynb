{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import libraries",
   "id": "9fc775b0561cfed5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-11T12:30:55.142517300Z",
     "start_time": "2026-01-11T12:30:54.772619200Z"
    }
   },
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Spark Session",
   "id": "367fa4fab550f656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:30:55.163523600Z",
     "start_time": "2026-01-11T12:30:55.150506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_spark():\n",
    "    \"\"\" Create a SparkSession object. \"\"\"\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"TestSuite\") \\\n",
    "        .config(key='spark.sql.shuffle.partitions', value='4') \\\n",
    "        .config(key='spark.default.parallelism', value='4') \\\n",
    "        .config(key='spark.sql.session.timeZone', value='UTC') \\\n",
    "        .config(key='spark.ui.enabled', value='false') \\\n",
    "        .config(key='spark.app.id', value='Test') \\\n",
    "        .config(key='spark.driver.host', value='localhost') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    return spark"
   ],
   "id": "158df046e1d5a21f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:31:22.082804800Z",
     "start_time": "2026-01-11T12:30:55.163523600Z"
    }
   },
   "cell_type": "code",
   "source": "spark = create_spark()",
   "id": "47f246f4b84cbb15",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "a9f963b048b85dd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:35:13.723842400Z",
     "start_time": "2026-01-11T12:35:12.667898200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_to_dataset = '../../dataset/amazon_electronics.csv'\n",
    "amazon_spark_df = spark.read.csv(path_to_dataset, header=True, inferSchema=True)"
   ],
   "id": "9bfa432980282184",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:35:13.903113900Z",
     "start_time": "2026-01-11T12:35:13.726851Z"
    }
   },
   "cell_type": "code",
   "source": "amazon_spark_df.show(5)",
   "id": "9abbf9d41ebc921",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------+----------+\n",
      "|       user_id|product_id|rating|timestamp |\n",
      "+--------------+----------+------+----------+\n",
      "| AKM1MP6P0OYPR| 132793040|     5|1365811200|\n",
      "|A2CX7LUOHB2NDG| 321732944|     5|1341100800|\n",
      "|A2NWSAGRHCP8N5| 439886341|     1|1367193600|\n",
      "|A2WNBOD3WNDNKT| 439886341|     3|1374451200|\n",
      "|A1GI0U4ZRJA8WN| 439886341|     1|1334707200|\n",
      "+--------------+----------+------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "130d2e2907e2ebe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:35:26.886803Z",
     "start_time": "2026-01-11T12:35:18.291820800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_indexer = StringIndexer(inputCol='user_id', outputCol='user_index')\n",
    "product_indexer = StringIndexer(inputCol='product_id', outputCol='product_index')\n",
    "\n",
    "indexed_data = user_indexer.fit(amazon_spark_df).transform(amazon_spark_df)\n",
    "indexed_data = product_indexer.fit(indexed_data).transform(indexed_data)"
   ],
   "id": "f326c69c3107db2d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split Dataset",
   "id": "90e2e93f5cbd1e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T12:35:28.915511600Z",
     "start_time": "2026-01-11T12:35:28.870726900Z"
    }
   },
   "cell_type": "code",
   "source": "train, test = indexed_data.randomSplit([0.8, 0.2], seed=42)",
   "id": "a8ef896d49535176",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build ALS model",
   "id": "ae9ceedecb7ab50c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "als = ALS(userCol='user_index',\n",
    "          itemCol='product_index',\n",
    "          ratingCol='rating',\n",
    "          coldStartStrategy='drop',\n",
    "          nonnegative=True)\n",
    "\n",
    "model = als.fit(train)"
   ],
   "id": "158b311eebdf2a81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "5c0ffd496d0cb0e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(labelCol='rating', metricName='rmse')\n",
    "rmse_score = evaluator.evaluate(predictions)\n",
    "print('RMSE: ', rmse_score)"
   ],
   "id": "ea10412d0f73a18f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 26/01/11 13:09:23 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
    "# 26/01/11 13:09:26 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
    "# 26/01/11 13:09:28 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
    "# 26/01/11 13:09:40 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
    "# 26/01/11 13:09:43 WARN DAGScheduler: Broadcasting large task binary with size 13.4 MiB\n",
    "# 26/01/11 13:09:45 WARN DAGScheduler: Broadcasting large task binary with size 13.4 MiB\n",
    "# 26/01/11 13:09:46 WARN DAGScheduler: Broadcasting large task binary with size 13.4 MiB\n",
    "# [Stage 224:>                                                        (0 + 4) / 4]\n",
    "# RMSE:  1.960614091465835"
   ],
   "id": "b4a79e575a901dd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Show first 5 predictions",
   "id": "65a60fa233df3310"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions.select('user_id', 'product_id', 'rating', 'prediction').show(5)",
   "id": "9a8f85895868d2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# +--------------+----------+------+----------+\n",
    "# |       user_id|product_id|rating|prediction|\n",
    "# +--------------+----------+------+----------+\n",
    "# | A680RUE1FDO8B|B0006ZKX7Y|     5|  4.024588|\n",
    "# | A680RUE1FDO8B|B000F9WYKA|     5|  4.008407|\n",
    "# | A680RUE1FDO8B|B000G0JD0C|     5| 3.6363602|\n",
    "# | A680RUE1FDO8B|B000I4PS3W|     5|   4.18065|\n",
    "# |A1F9Z42CFF9IAY|B00009KAPW|     1| 3.6061687|\n",
    "# +--------------+----------+------+----------+\n",
    "# only showing top 5 rows"
   ],
   "id": "57708a7435ada5e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
