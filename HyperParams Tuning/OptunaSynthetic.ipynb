{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:53:47.500817100Z",
     "start_time": "2025-12-28T09:53:47.484335100Z"
    }
   },
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, GradientBoostingRegressor, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from optuna.trial import Trial, FrozenTrial\n",
    "from optuna.study import Study, StudyDirection\n",
    "from optuna.visualization import  plot_optimization_history, plot_parallel_coordinate\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, GridSearchCV"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T09:51:33.504563300Z",
     "start_time": "2025-12-28T09:51:33.484323300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "id": "55d38996cb1d772",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T09:51:33.519337500Z",
     "start_time": "2025-12-28T09:51:33.507087200Z"
    }
   },
   "cell_type": "code",
   "source": "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)",
   "id": "86a3c3ebe05f8db9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T09:51:33.539105400Z",
     "start_time": "2025-12-28T09:51:33.523510900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EarlyStoppingCallback:\n",
    "    \"\"\"\n",
    "    Early stopping callback for Optuna studies.\n",
    "    Stops the study if there is no improvement in the best value for a specified number of trials (patience).\n",
    "    \"\"\"\n",
    "    def __init__(self, patience: int, min_delta: float = 0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of trials to wait for improvement before stopping.\n",
    "            min_delta (float): Minimum change in the monitored value to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_value = None\n",
    "\n",
    "    def __call__(self, study: Study, trial: FrozenTrial):\n",
    "        if self.best_value is None:\n",
    "            self.best_value = study.best_value\n",
    "            return\n",
    "\n",
    "        if study.direction == StudyDirection.MINIMIZE:\n",
    "            if study.best_value < self.best_value - self.min_delta:\n",
    "                self.best_value = study.best_value\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        else:\n",
    "            if study.best_value > self.best_value + self.min_delta:\n",
    "                self.best_value = study.best_value\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            study.stop()\n",
    "            print(f'Early stopping triggered after {self.counter} trials with no improvement.')"
   ],
   "id": "ac1e259895e26c62",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial: Trial):\n",
    "\n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 100, 1000),\n",
    "        criterion=trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "        max_depth=trial.suggest_int('max_depth', 5, 50),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 32),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 32),\n",
    "        min_weight_fraction_leaf=trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.5, step=0.05),\n",
    "        bootstrap=True,\n",
    "        # bootstrap=trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        oob_score=trial.suggest_categorical('oob_score', [True, False]),\n",
    "        ccp_alpha=trial.suggest_float('ccp_alpha', 0.0, 0.1, step=0.01),\n",
    "        n_jobs=-1\n",
    "    ) # 0.8610047172921425\n",
    "\n",
    "    # model = LogisticRegression(\n",
    "    #     C=trial.suggest_float('C', 0.01, 10.0, log=True),\n",
    "    #     max_iter=trial.suggest_int('max_iter', 100, 1000),\n",
    "    #     tol=trial.suggest_float('tol', 1e-5, 1e-1, log=True),\n",
    "    #     solver=trial.suggest_categorical('solver', ['saga']),\n",
    "    #     penalty=trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet']),\n",
    "    #     l1_ratio=trial.suggest_float('l1_ratio', 0.0, 1.0) if trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet']) == 'elasticnet' else None,\n",
    "    #     n_jobs=-1\n",
    "    # ) # 0.8160286034537533\n",
    "\n",
    "    # model = GradientBoostingClassifier(\n",
    "    #     n_estimators=trial.suggest_int('n_estimators', 100, 1000),\n",
    "    #     max_depth=trial.suggest_int('max_depth', 3, 20),\n",
    "    #     learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3, step=0.01),\n",
    "    #     subsample=trial.suggest_float('subsample', 0.5, 1.0, step=0.1)\n",
    "    # ) # 0.9310178441914969\n",
    "\n",
    "    # model = KNeighborsClassifier(\n",
    "    #     n_neighbors=trial.suggest_int('n_neighbors', 1, 100),\n",
    "    #     weights=trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "    #     leaf_size=trial.suggest_int('leaf_size', 10, 5000),\n",
    "    #     p=trial.suggest_float('p', low=0.1, high=4, step=0.025),\n",
    "    #     n_jobs=-1\n",
    "    # ) # 0.9329958701216187\n",
    "\n",
    "    score = cross_val_score(model,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            n_jobs=-1,\n",
    "                            cv=cv,\n",
    "                            scoring='accuracy')\n",
    "\n",
    "    accuracy = score.mean()\n",
    "    return accuracy"
   ],
   "id": "22eb2de6adcf59ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study = create_study(direction='maximize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=200, n_jobs=-1, callbacks=[EarlyStoppingCallback(patience=5, min_delta=1e-4)])"
   ],
   "id": "fd8c3bb1b07de6e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study.best_params",
   "id": "4aab339b234f0244",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study.best_value",
   "id": "ddcce2417f791d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_parallel_coordinate(study)",
   "id": "582b762a21e9ea6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T09:51:33.555122Z",
     "start_time": "2025-12-28T09:51:33.541127700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "knn_model = KNeighborsClassifier(**{'n_neighbors': 12, 'weights': 'distance', 'leaf_size': 2325, 'p': 1.0250000000000001}) # 0.9280028531525537\n",
    "gbc_model = GradientBoostingClassifier(**{'n_estimators': 497, 'max_depth': 6, 'learning_rate': 0.14, 'subsample': 0.6})   # 0.927016837196478\n",
    "etree_model = ExtraTreesClassifier(**{'n_estimators': 996, 'criterion': 'log_loss', 'max_depth': 50, 'min_samples_split': 4,\n",
    " 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.0, 'oob_score': False, 'ccp_alpha': 0.0}) # 0.8669987352622083"
   ],
   "id": "a7700dc208d0ae06",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T09:55:18.049373300Z",
     "start_time": "2025-12-28T09:55:07.396148300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = [knn_model, gbc_model, etree_model]\n",
    "for model in models:\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    score = cross_val_score(model,\n",
    "                            X_test,\n",
    "                            y_test,\n",
    "                            n_jobs=-1,\n",
    "                            cv=cv,\n",
    "                            scoring='accuracy')\n",
    "    accuracy = score.mean()\n",
    "    print(f'{model.__class__.__name__} Cross Validation Score: {accuracy}')"
   ],
   "id": "34d0f34eceeeaa3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier Cross Validation Score: 0.8203678576812905\n",
      "GradientBoostingClassifier Cross Validation Score: 0.8399668325041459\n",
      "ExtraTreesClassifier Cross Validation Score: 0.7799638172772502\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T09:52:54.496869500Z",
     "start_time": "2025-12-28T09:52:39.575442700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estimators=[('knn', knn_model), ('gbc', gbc_model), ('etree', etree_model)]\n",
    "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "cross_voting_score = cross_val_score(voting_clf, X_test, y_test, cv=cv, n_jobs=-1, scoring='accuracy').mean()\n",
    "print(f'Voting Classifier Cross Validation Score: {cross_voting_score}')"
   ],
   "id": "b4cc0b1f04f4aea8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Cross Validation Score: 0.8450927182270466\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T09:54:28.834222500Z",
     "start_time": "2025-12-28T09:53:51.390077100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tuning\n",
    "param_grid = {\n",
    "    'voting': ['hard', 'soft'],\n",
    "    'weights': [[1, 1, 1], [2, 1, 1], [1, 1, 2], [1, 2, 1]]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=voting_clf,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=cv,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1,\n",
    "                           scoring='accuracy',\n",
    "                           return_train_score=False)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Model: {best_model}')\n",
    "print(f'Best Score: {best_score}') # Best Score: 0.9312560427285442"
   ],
   "id": "d6c4fbc589a4ab04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'voting': 'soft', 'weights': [2, 1, 1]}\n",
      "Best Model: VotingClassifier(estimators=[('knn',\n",
      "                              KNeighborsClassifier(leaf_size=2325,\n",
      "                                                   n_neighbors=12,\n",
      "                                                   p=1.0250000000000001,\n",
      "                                                   weights='distance')),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(learning_rate=0.14,\n",
      "                                                         max_depth=6,\n",
      "                                                         n_estimators=497,\n",
      "                                                         subsample=0.6)),\n",
      "                             ('etree',\n",
      "                              ExtraTreesClassifier(criterion='log_loss',\n",
      "                                                   max_depth=50,\n",
      "                                                   min_samples_leaf=9,\n",
      "                                                   min_samples_split=4,\n",
      "                                                   n_estimators=996))],\n",
      "                 voting='soft', weights=[2, 1, 1])\n",
      "Best Score: 0.9312560427285442\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_model = RandomForestRegressor(\n",
    "    **study.best_params,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Train performance\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Test performance\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Train RMSE: {rmse_train:.3f}\")\n",
    "print(f\"Test RMSE:  {rmse_test:.3f}\")\n",
    "\n",
    "# If rmse_train << rmse_test → likely overfitting.\n",
    "# If both are high → likely underfitting.\n",
    "# If both are reasonably close and low → model is well fit."
   ],
   "id": "3d81920776881359"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# best params from your Optuna study (classification)\n",
    "best_clf = ExtraTreesClassifier(\n",
    "    **study.best_params,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 1. Train on full training set\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# 2. Accuracy on training set\n",
    "y_train_pred = best_clf.predict(X_train)\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# 3. Accuracy on test set (hold-out set)\n",
    "y_test_pred = best_clf.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f}\")\n",
    "print(f\"Gap (train - test): {acc_train - acc_test:.3f}\")\n",
    "\n",
    "# 4. (optional) Cross-validation on training set with fixed best_clf\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_clf, X_train, y_train, cv=cv, n_jobs=-1, scoring=\"accuracy\")\n",
    "print(f\"CV mean accuracy (train side): {cv_scores.mean():.3f}, std: {cv_scores.std():.3f}\")\n",
    "\n",
    "# Heuristics:\n",
    "# - If acc_train and acc_test are both high and close -> model is likely stable.\n",
    "# - If acc_train >> acc_test -> overfitting.\n",
    "# - If both are low -> underfitting.\n",
    "# - If CV accuracy ~= test accuracy and does not improve with more trials/models -> stabilized."
   ],
   "id": "592b8338f16b1fac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
