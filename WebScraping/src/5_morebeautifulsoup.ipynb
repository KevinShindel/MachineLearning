{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we take a look at a couple more examples using Beautiful Soup. We'll mainly use the `select` method here to illustrate the use of CSS selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Books to Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first example, we'll use http://books.toscrape.com/. Play around a bit with this website to see how it works. We're going to scrape the details for all books.\n",
    "\n",
    "Note: this website also illustrates the importance of checking how a site handles pagination. Here, we can use `http://books.toscrape.com/catalogue/page-XXX.html`, and we see that the site returns a 404 status in case the page doesn't exist. This is not always the case. E.g. some sites will show an empty listing, whereas others might show the last (existing) page again, requiring a manual double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Scraping page 18\n",
      "Scraping page 19\n",
      "Scraping page 20\n",
      "Scraping page 21\n",
      "Scraping page 22\n",
      "Scraping page 23\n",
      "Scraping page 24\n",
      "Scraping page 25\n",
      "Scraping page 26\n",
      "Scraping page 27\n",
      "Scraping page 28\n",
      "Scraping page 29\n",
      "Scraping page 30\n",
      "Scraping page 31\n",
      "Scraping page 32\n",
      "Scraping page 33\n",
      "Scraping page 34\n",
      "Scraping page 35\n",
      "Scraping page 36\n",
      "Scraping page 37\n",
      "Scraping page 38\n",
      "Scraping page 39\n",
      "Scraping page 40\n",
      "Scraping page 41\n",
      "Scraping page 42\n",
      "Scraping page 43\n",
      "Scraping page 44\n",
      "Scraping page 45\n",
      "Scraping page 46\n",
      "Scraping page 47\n",
      "Scraping page 48\n",
      "Scraping page 49\n",
      "Scraping page 50\n",
      "Scraping page 51\n"
     ]
    }
   ],
   "source": [
    "page = 1\n",
    "results = []\n",
    "\n",
    "while True:\n",
    "    print('Scraping page', page)\n",
    "    p = requests.get('http://books.toscrape.com/catalogue/page-{}.html'.format(page))\n",
    "    page += 1\n",
    "    if p.status_code == 404:\n",
    "        break\n",
    "    soup = BeautifulSoup(p.text, 'html.parser')\n",
    "    books = soup.select('.product_pod')\n",
    "    for book in books:\n",
    "        book_title = book.find('img').get('alt')\n",
    "        book_link = book.find('a').get('href')\n",
    "        book_rating = book.find(class_='star-rating').get('class')\n",
    "        book_price = book.find(class_='price_color').get_text(strip=True)\n",
    "        results.append({\n",
    "            'book_title': book_title,\n",
    "            'book_link': book_link,\n",
    "            'book_rating': book_rating,\n",
    "            'book_price': book_price\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book_title': 'A Light in the Attic',\n",
       "  'book_link': 'a-light-in-the-attic_1000/index.html',\n",
       "  'book_rating': ['star-rating', 'Three'],\n",
       "  'book_price': 'Â£51.77'},\n",
       " {'book_title': 'Tipping the Velvet',\n",
       "  'book_link': 'tipping-the-velvet_999/index.html',\n",
       "  'book_rating': ['star-rating', 'One'],\n",
       "  'book_price': 'Â£53.74'},\n",
       " {'book_title': 'Soumission',\n",
       "  'book_link': 'soumission_998/index.html',\n",
       "  'book_rating': ['star-rating', 'One'],\n",
       "  'book_price': 'Â£50.10'},\n",
       " {'book_title': 'Sharp Objects',\n",
       "  'book_link': 'sharp-objects_997/index.html',\n",
       "  'book_rating': ['star-rating', 'Four'],\n",
       "  'book_price': 'Â£47.82'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good. Let's try this again, but fixing two elements:\n",
    "\n",
    "- For the rating, we'll convert the rating to an actual number\n",
    "- The price seems incorrectly parsed. This is due to Requests misinterpreting the encoding in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISO-8859-1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did Requests think the encoding is `ISO-8859-1`? Let's take a look at the headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Server': 'nginx/1.14.0 (Ubuntu)', 'Date': 'Fri, 31 Jul 2020 09:42:31 GMT', 'Content-Type': 'text/html', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'X-Upstream': 'toscrape-books-master_web', 'Content-Encoding': 'gzip'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No extra information here, so Requests sticks to the default (`ISO-8859-1`), but in the HTML, we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n<!DOCTYPE html>\\n<!--[if lt IE 7]>      <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\\n<!--[if IE 7]>         <html lang=\"en-us\" class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\\n<!--[if IE 8]>         <html lang=\"en-us\" class=\"no-js lt-ie9\"> <![endif]-->\\n<!--[if gt IE 8]><!--> <html lang=\"en-us\" class=\"no-js\"> <!--<![endif]-->\\n    <head>\\n        <title>\\n    All products | Books to Scrape - Sandbox\\n</title>\\n\\n        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" />\\n        <meta name=\"created\" content=\"24th Jun 2016 09:30\" />\\n        <meta name=\"description\" c'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://books.toscrape.com/catalogue/page-{}.html'.format(1)).text[:600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I.e. `<meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" />`. So we will also override Requests here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Scraping page 18\n",
      "Scraping page 19\n",
      "Scraping page 20\n",
      "Scraping page 21\n",
      "Scraping page 22\n",
      "Scraping page 23\n",
      "Scraping page 24\n",
      "Scraping page 25\n",
      "Scraping page 26\n",
      "Scraping page 27\n",
      "Scraping page 28\n",
      "Scraping page 29\n",
      "Scraping page 30\n",
      "Scraping page 31\n",
      "Scraping page 32\n",
      "Scraping page 33\n",
      "Scraping page 34\n",
      "Scraping page 35\n",
      "Scraping page 36\n",
      "Scraping page 37\n",
      "Scraping page 38\n",
      "Scraping page 39\n",
      "Scraping page 40\n",
      "Scraping page 41\n",
      "Scraping page 42\n",
      "Scraping page 43\n",
      "Scraping page 44\n",
      "Scraping page 45\n",
      "Scraping page 46\n",
      "Scraping page 47\n",
      "Scraping page 48\n",
      "Scraping page 49\n",
      "Scraping page 50\n",
      "Scraping page 51\n"
     ]
    }
   ],
   "source": [
    "page = 1\n",
    "results = []\n",
    "\n",
    "ratings = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five']\n",
    "\n",
    "while True:\n",
    "    print('Scraping page', page)\n",
    "    p = requests.get('http://books.toscrape.com/catalogue/page-{}.html'.format(page))\n",
    "    p.encoding = 'UTF-8'\n",
    "    page += 1\n",
    "    if p.status_code == 404:\n",
    "        break\n",
    "    soup = BeautifulSoup(p.text, 'html.parser')\n",
    "    books = soup.select('.product_pod')\n",
    "    for book in books:\n",
    "        book_title = book.find('img').get('alt')\n",
    "        book_link = book.find('a').get('href')\n",
    "        book_rating = ratings.index(book.find(class_='star-rating').get('class')[1])\n",
    "        book_price = book.find(class_='price_color').get_text(strip=True)\n",
    "        results.append({\n",
    "            'book_title': book_title,\n",
    "            'book_link': book_link,\n",
    "            'book_rating': book_rating,\n",
    "            'book_price': book_price\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book_title': 'A Light in the Attic',\n",
       "  'book_link': 'a-light-in-the-attic_1000/index.html',\n",
       "  'book_rating': 3,\n",
       "  'book_price': '£51.77'},\n",
       " {'book_title': 'Tipping the Velvet',\n",
       "  'book_link': 'tipping-the-velvet_999/index.html',\n",
       "  'book_rating': 1,\n",
       "  'book_price': '£53.74'},\n",
       " {'book_title': 'Soumission',\n",
       "  'book_link': 'soumission_998/index.html',\n",
       "  'book_rating': 1,\n",
       "  'book_price': '£50.10'},\n",
       " {'book_title': 'Sharp Objects',\n",
       "  'book_link': 'sharp-objects_997/index.html',\n",
       "  'book_rating': 4,\n",
       "  'book_price': '£47.82'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Zalando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll scrape some product information from the Zalando web store. Note that this example is already more complicated. We'll need to import the regex module as we'll need it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to scrape a number of womens dresses. Also not the custom `User-Agent` defined below. If we don't do so, Zalando will block our requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.zalando.co.uk/womens-clothing-dresses/'\n",
    "pages_to_crawl = 2\n",
    "headers = {\n",
    "    'User-Agent': \n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of things we need to keep in mind here:\n",
    "\n",
    "- First, getting a reliable list of articles is pretty tricky. You can e.g. also use `select('#z-nvg-cognac-root z-grid-item')` here, but this will return a couple of additional elements which do not actually correspond with pages\n",
    "- As such, we also include the class here. However, we still get one additional element at the end not containing an actual article, which is what the `if` condition is for\n",
    "- Also, we're selecting on classes here, but a lot of the class names Zalando uses have strange names, e.g. `class=\"cat_brandName-2XZRz cat_ellipsis-MujnT\"`. Always try to make scrapers as robust as possible. As such, we might believe that the class suffixes here are auto-generated (e.g. by some CSS middleware toolkit). We'll hence use regex to match with the beginning part only\n",
    "- Luckily for us, regex expressions and functions can also be used to filter on attributes\n",
    "- Try to expand this example to get brand names, original price and discounted price (if available) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page: 1\n",
      " - Maxi dress - almond /billabong-maxi-dress-almond-bi721c03g-b11.html\n",
      " - BE RIDER - Day dress - black /roxy-be-rider-day-dress-anthracite-ro521c04s-q11.html\n",
      " - BE RIDER - Day dress - mood indigo /roxy-be-rider-day-dress-mood-indigo-ro521c04s-k11.html\n",
      " - VIGRETA ANCLE DRESS - Day dress - samoan sun /vila-vigreta-ancle-dress-day-dress-samoan-sun-v1021c205-e11.html\n",
      " - Maxi dress - black/rose/dark green /anna-field-curvy-jersey-dress-blackrosedark-green-ax821c03n-q11.html\n",
      " - Maxi dress - turquoise /anna-field-curvy-maxi-dress-turquoise-ax821c03y-l11.html\n",
      " - TEE DRESS - Jersey dress - black /adidas-originals-tee-dress-jersey-dress-black-ad121c05r-q11.html\n",
      " - ABREUVOIR - Day dress - white /derhy-abreuvoir-day-dress-rd521c0h5-a11.html\n",
      " - RARE FEELING - Maxi dress - black /free-people-rare-feeling-maxi-maxi-dress-black-fp021c07o-q11.html\n",
      " - Denim dress - light blue denim /vero-moda-denim-dress-light-blue-denim-ve121c1ak-k11.html\n",
      " - UNGEFÜTTERT LANG - Day dress - varicolored /betty-and-co-ungefuettert-lang-day-dress-varicolored-b0n21c03d-t11.html\n",
      " - Jersey dress - maritime blue /anna-field-curvy-jersey-dress-maritime-blue-ax821c03w-k11.html\n",
      " - Occasion wear - dark blue /anna-field-jersey-dress-dark-blue-an621c1i8-k11.html\n",
      " - ALINE ZIP BOUCLE - Jumper dress - true black /gap-tall-aline-zip-boucle-jumper-dress-true-black-gah21c005-q11.html\n",
      " - CALCARONE - Day dress - off white /derhy-calcarone-maxi-dress-off-white-rd521c0i5-a11.html\n",
      " - FINE FLUTTER - Day dress - pistachio /billabong-day-dress-pistachio-bi721c02v-b11.html\n",
      " - BABY CRUSH - Jumper dress - ash rose /roxy-baby-crush-jumper-dress-ash-rose-ro521c04r-j11.html\n",
      " - WM HI ROLLER - Jersey dress - black /vans-day-dress-black-va221c01s-q11.html\n",
      " - AVRIL DRESS - Shirt dress - yellow /monki-avril-dress-shirt-dress-yellow-moq21c08p-e11.html\n",
      " - TANK DRESS - Shift dress - team royal blue/white /adidas-originals-tank-dress-jersey-dress-ad121c057-k11.html\n",
      " - TJW ESSENTIAL  - Day dress - marine (52) /tommy-jeans-tjw-essential-day-dress-marine-52-tob21c04a-k11.html\n",
      " - Day dress - ecru/multi /trendyol-day-dress-ecrumulti-tru21c05u-t11.html\n",
      " - ENCART ROBE - Maxi dress - multi coloured /derhy-encart-robe-maxi-dress-multi-coloured-rd521c0ii-t11.html\n",
      " - CUT & SEW OVERSIZED DRESS VARSITY - Day dress - multi /jaded-london-cut-and-sew-oversized-dress-varsity-day-dress-multi-jl021c02a-t11.html\n",
      " - JDYSANSA DRESS RAW  - Denim dress - medium blue denim /jdy-jdysansa-dress-raw-denim-dress-medium-blue-denim-jy121c0d1-k11.html\n",
      " - ESTHER DRESS - Day dress - black /gina-tricot-esther-dress-day-dress-black-gid21c04t-q11.html\n",
      " - Jersey dress - black/white /anna-field-curvy-jersey-dress-blackwhite-ax821c03t-q11.html\n",
      " - TANK DRESS - Shift dress - black/white /adidas-originals-tank-dress-jersey-dress-blackwhite-ad121c057-q11.html\n",
      " - VIJESSAS DRESS - Shirt dress - cloud dancer /vila-petite-vijessas-dress-shirt-dress-cloud-dancer-vip21c00r-a11.html\n",
      " - Cocktail dress / Party dress - schwarz /swing-cocktail-dress--party-dress-schwarz-sg721c0cv-q11.html\n",
      " - Shift dress - black /anna-field-cocktail-dress-party-dress-black-an621c1k9-q11.html\n",
      " - Jumper dress - noir/lipstick /morgan-jumper-dress-noirlipstick-m5921c0n5-q11.html\n",
      "Scraping page: 2\n",
      " - TANK DRESS - Jersey dress - multicolor /adidas-originals-tank-dress-jersey-dress-multicolor-ad121c05e-j11.html\n",
      " - Jumper dress - white /evenandodd-jumper-dress-white-ev421c0zt-a11.html\n",
      " - Jersey dress - bright graffiti print /jaded-london-jersey-dress-bright-graffiti-print-jl021c023-t11.html\n",
      " - PCMALUKI 3/4 DRESS - Day dress - navy blazer /pieces-petite-pcmaluki-34-dress-day-dress-navy-blazer-pit21c008-t11.html\n",
      " - Shirt dress - black /vero-moda-shirt-dress-black-ve121c2ap-q11.html\n",
      " - AVENUE DRESS - Shift dress - nude /4th-and-reckless-avenue-dress-day-dress-nude-4t021c026-j11.html\n",
      " - ONLROCKY 7/8 SMOCK MIDI DRESS - Shirt dress - black/rocky rose /only-onlrocky-78-smock-midi-dress-shirt-dress-blackrocky-rose-on321c1mt-q11.html\n",
      " - LANGES ROMANTISCHES KLEID 31990115 - Day dress - red /oysho-langes-romantisches-kleid-31990115-day-dress-red-oy121c050-g11.html\n",
      " - MIRANDA DRESS ASIA - Shirt dress - lilac /monki-miranda-dress-shirt-dress-moq21c05o-i12.html\n",
      " - Denim dress - blue /defacto-denim-dress-blue-dez21c06c-k11.html\n",
      " - Day dress - limelight/bright cactus/ice silver /nike-sportswear-air-hoodie-dress-shirt-dress-ni121c01m-m11.html\n",
      " - JEARSEYKLEID BASIC - Jersey dress - black /evenandodd-jersey-dress-black-ev421c0zg-q11.html\n",
      " - VMDELTA DRESS - Shirt dress - beige /vero-moda-vmdelta-dress-day-dress-ve121c260-b11.html\n",
      " - SIDE SLIT MIDI - Jumper dress - white /abercrombie-and-fitch-jumper-dress-white-a0f21c03b-a11.html\n",
      " - SHORT SLEEVE TIERED DRESS - Maxi dress - white /glamorous-short-sleeve-tiered-dress-maxi-dress-white-gl921c0kk-a11.html\n",
      " - ALMA - Jersey dress - dark blue/white /tom-joule-alma-jersey-dress-dark-bluewhite-4jo21c04l-k11.html\n",
      " - LONG DRESS PETIT - Maxi dress - gardenia /object-petite-long-dress-petit-maxi-dress-gardenia-ob821c011-a11.html\n",
      " - RETRO FEMME DRESS - Jersey dress - track red /nike-sportswear-retro-femme-dress-jersey-dress-track-red-ni121c01s-t11.html\n",
      " - VMWONDA WRAP DRESS - Maxi dress - jadeite/asta /vero-moda-vmwonda-wrap-dress-maxi-dress-jadeiteasta-ve121c293-m11.html\n",
      " - MICHIGAN PINAFORE - Denim dress - desert /drdenim-michigan-pinafore-day-dress-dr121c00o-b11.html\n",
      " - YASALVA 3/4 DRESS - Day dress - pink nectar /yas-yasalva-34-dress-day-dress-pink-nectar-y0121c17p-j11.html\n",
      " - VMFALLIE - Day dress - black/fallie /vero-moda-vmfallie-day-dress-ve121c1yh-q11.html\n",
      " - FRJEDOT  - Jersey dress - navy blazer mix /fransa-frjedot-day-dress-navy-blazer-mix-f2121c049-k11.html\n",
      " - VMGAMMA WRAP DRESS - Day dress - black/nice /vero-moda-vmgamma-wrap-dress-day-dress-ve121c1zy-q11.html\n",
      " - MIT FLECKENPRINT - Jersey dress - black /oysho-mit-fleckenprint-jersey-dress-black-oy121c04u-q11.html\n",
      " - Jersey dress - black /yours-clothing-jersey-dress-black-yod21c04m-q11.html\n",
      " - BASIC JERSEYKLEID - Shift dress - mottled dark grey /evenandodd-jersey-dress-mottled-dark-grey-ev421c124-c11.html\n",
      " - MINI DELORES DRESS - Day dress - pink /never-fully-dressed-day-dress-pink-nen21c00b-j11.html\n",
      " - Shirt dress - white /massimo-dutti-shirt-dress-white-m3i21c0af-a11.html\n",
      " - INDIA - Day dress - blue /desigual-india-day-dress-blue-de121c0nj-k11.html\n",
      " - LIZ DRESS - Day dress - beige /love-copenhagen-liz-dress-day-dress-beige-l1g21c01z-o11.html\n",
      " - DAMIRA SHIRTDRESS - Shirt dress - lilac pink light /monki-damira-shirtdress-shirt-dress-lilac-pink-light-moq21c03w-j11.html\n"
     ]
    }
   ],
   "source": [
    "for p in range(1, pages_to_crawl+1):\n",
    "    print('Scraping page:', p)\n",
    "    r = requests.get(url, params={'p' : p}, headers=headers)\n",
    "    html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    for article in html_soup.find_all('z-grid-item', class_=re.compile('^cat_card')):\n",
    "        article_info = article.find(class_=re.compile('^cat_infoDetail'))\n",
    "        if article_info is None:\n",
    "            continue\n",
    "        article_name = article.find(class_=re.compile('^cat_articleName')).get_text(strip=True)\n",
    "        print(' -', article_name, article_info.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
