{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying ðŸ¤— HuggingFace Transformers\n",
    "\n",
    "Make sure you install the dependencies from `requirements.txt` before executing cells in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:45:44.240498Z",
     "start_time": "2025-05-12T11:45:32.747343Z"
    }
   },
   "source": [
    "from transformers import pipeline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generator pipeline. In this case, use the `text2text` for NLP processing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:45:48.398082Z",
     "start_time": "2025-05-12T11:45:44.449227Z"
    }
   },
   "source": [
    "generator = pipeline(\"text2text-generation\", model=\"t5-base\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tymur_Hilfatullin\\Projects\\try-huggingface\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e97814a4bd143a8804cc6d4290f75e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tymur_Hilfatullin\\Projects\\try-huggingface\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Tymur_Hilfatullin\\.cache\\huggingface\\hub\\models--t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:45:54.635482Z",
     "start_time": "2025-05-12T11:45:53.799923Z"
    }
   },
   "source": [
    "# Summarize\n",
    "generator(\"summarize: Machine Learning in production environments is largely seen as the ultimate goal. Sometimes, deploying models can be difficult when automation is not part of the workflow. Creating a foundational process that is reliable and automated is complex and requires commitment from the team and the organization as a whole\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'machine learning is a key to a successful production environment . a foundational process that'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:50:23.668187Z",
     "start_time": "2025-05-12T11:50:23.522373Z"
    }
   },
   "source": [
    "# Sentiment\n",
    "generator(\"sst2 sentence: Automation takes hard work but allows you to have a solid deployment\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'positive'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:50:35.944797Z",
     "start_time": "2025-05-12T11:50:35.711402Z"
    }
   },
   "source": [
    "# Questions\n",
    "generator(\"question: Is deploying models into production hard?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'not_entailment'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:51:11.325652Z",
     "start_time": "2025-05-12T11:51:10.614154Z"
    }
   },
   "source": [
    "# Translation\n",
    "generator(\"translate English to French: Automation takes hard work but allows you to have a solid deployment\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"L'automatisation exige beaucoup de travail, mais vous permet d'avoir un dÃ©plo\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create other generation objects by calling in other models as well"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:51:51.345327Z",
     "start_time": "2025-05-12T11:51:22.705206Z"
    }
   },
   "source": [
    "gpt2_generator = pipeline(\"text-generation\", model=\"gpt2\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6975dd8d45b2412798183f9ba4832f50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tymur_Hilfatullin\\Projects\\try-huggingface\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Tymur_Hilfatullin\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dba9a72b1928492f944fe525b865e577"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7d7ebf4699b4de392c3498009638305"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b98cd4b0b0094990b38685a97df9ab49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "accaa254a41e4ff4b0b8b8ab6251c068"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9230722487e04d1aab1ef618470578e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb2fc82caa7b4f8c9d1d95649ba2ca59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:53:27.175384Z",
     "start_time": "2025-05-12T11:53:14.767747Z"
    }
   },
   "source": [
    "gpt2_generator(\"some phrase here was thought to be\", max_new_tokens=512)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'some phrase here was thought to be used for the \"sugar daddy.\"\\n\\nNow it may be overstated, but it\\'s certainly an amusing, amusing joke!\\n\\nIn January of 2017, CBS News reported that a senior official at FOX did not want to be named in the show. In fact, in the transcript read to CBS, he said, \"The show will show an old movie character [who] could be in the future. What better way to do that than to write about being one of the greatest entertainers of all time [who] will be retiring sometime in 2018 rather than when that character is supposed to be retired?\" Well, we may be getting a bit closer to that than we were last year, but let\\'s get straight to the point: FOX President Roger Sterling has told a reporter that his decision about the new show to play in 2017 will be made before the show \"significantly changes how we talk about the industry as in the past.\" Well, well, if that\\'s true, why not do it after Fox declined to join the franchise, too?\\n\\nIt\\'s not a lot to ask for to be doing an old-school show like this anymore. In fact, not only would it be cool but it would allow for an even more interesting, nuanced storytelling that was also part of their prior show. Yes, a lot of younger folks may not have heard of Star Trek, yet there\\'s still plenty of Star Trek: Insurrection to be known about. It\\'s also great that there is a great number of older creators involved.\\n\\nWith all these new Star Trek, you shouldn\\'t have to find other writers, filmmakers, and actors. That said, it\\'s also going to be nice to know what these new characters will bring to the show. Is it any wonder they can do it at such a rapid pace? Will our generation of geek-watchers realize that this isn\\'t just a way to watch a show called \"The Simpsons\"?\\n\\nAs for meâ€¦ The series isn\\'t going anywhere, but there are so many things at stake, in this world, that my life is going to be much more difficult when I retire. So, let\\'s just take a breather and get some sleepâ€¦\\n\\n[Photo by David Lee/Getty Images]'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('huggingface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "920d5173f2c6743f2c8a5baff36bfaa747ac4cb3d34512c636ba17b43fdf31dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
