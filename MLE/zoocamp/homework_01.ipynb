{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:32:07.676428Z",
     "start_time": "2025-05-06T08:32:07.672302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error"
   ],
   "id": "fda9bd945c739430",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:32:10.219616Z",
     "start_time": "2025-05-06T08:32:07.721538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "yellow_taxi_january_2023_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet'\n",
    "yellow_taxi_february_2023_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet'\n",
    "\n",
    "df = pd.read_parquet(yellow_taxi_january_2023_url)\n",
    "\n",
    "print(len(df.columns))"
   ],
   "id": "6cbc14977b46d937",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Download the data for January and February 2023.\n",
    "\n",
    "Q: Read the data for January. How many columns are there?\n",
    "\n",
    "A: 19"
   ],
   "id": "a2629ec70d63eb0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:32:15.922001Z",
     "start_time": "2025-05-06T08:32:10.250128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "df.duration.std()"
   ],
   "id": "e07ac9119a09a5fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(42.59435124195458)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Q2. Computing duration\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "Q: What's the standard deviation of the trips duration in January?\n",
    "\n",
    "A: 42.59"
   ],
   "id": "10070e10c024afd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:32:16.297063Z",
     "start_time": "2025-05-06T08:32:15.950833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert duration to minutes first\n",
    "df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "\n",
    "# Calculate total number of records before filtering\n",
    "total_records = len(df)\n",
    "\n",
    "# Filter records between 1 and 60 minutes (inclusive)\n",
    "# Convert duration to minutes\n",
    "df_filtered = df[(df['duration'].dt.total_seconds()/60 >= 1) &\n",
    "                 (df['duration'].dt.total_seconds()/60 <= 60)]\n",
    "\n",
    "# Calculate number of records after filtering\n",
    "filtered_records = len(df_filtered)\n",
    "\n",
    "\n",
    "# Calculate the fraction\n",
    "fraction = filtered_records / total_records\n",
    "\n",
    "print(f\"Original number of records: {total_records}\")\n",
    "print(f\"Records after filtering: {filtered_records}\")\n",
    "print(f\"Fraction remaining: {fraction:.4f}\")\n",
    "print(f\"Percentage remaining: {fraction * 100:.2f}%\")\n"
   ],
   "id": "ce405d6b881bad3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of records: 3066766\n",
      "Records after filtering: 3009173\n",
      "Fraction remaining: 0.9812\n",
      "Percentage remaining: 98.12%\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Q3. Dropping outliers\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "Q: What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "A: 98%"
   ],
   "id": "15ff6ba29c5484fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:32:34.374752Z",
     "start_time": "2025-05-06T08:32:16.325260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "# Fit a dictionary vectorizer\n",
    "# Get a feature matrix from it\n",
    "df = pd.read_parquet(yellow_taxi_january_2023_url)\n",
    "df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "df[categorical] = df[categorical].astype(str)\n",
    "train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "# Create and fit the DictVectorizer\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Get number of columns (dimensionality)\n",
    "n_features = X.shape[1]\n",
    "print(f\"Number of features (columns): {n_features}\")"
   ],
   "id": "9f2a4de03a3c29a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (columns): 516\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Q4. One-hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "Fit a dictionary vectorizer\n",
    "Get a feature matrix from it\n",
    "\n",
    "Q: What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "A: 515"
   ],
   "id": "b84a9641ae002d29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:32:37.147149Z",
     "start_time": "2025-05-06T08:32:34.404497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target = 'duration'\n",
    "y_train = df[target].values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y_train)\n",
    "\n",
    "y_pred = lr.predict(X)\n",
    "\n",
    "root_mean_squared_error(y_train, y_pred)"
   ],
   "id": "b0610cec7db390ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.658403836937678"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Q5. Training a model\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "Train a plain linear regression model with default parameters, where duration is the response variable\n",
    "Calculate the RMSE of the model on the training data\n",
    "\n",
    "Q: What's the RMSE on train?\n",
    "\n",
    "A: 7.64"
   ],
   "id": "1a9c5e477e7ff73a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:32:54.686943Z",
     "start_time": "2025-05-06T08:32:37.182727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feb_df = pd.read_parquet(yellow_taxi_february_2023_url)\n",
    "\n",
    "feb_df['duration'] = feb_df.tpep_dropoff_datetime - feb_df.tpep_pickup_datetime\n",
    "feb_df.duration = feb_df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "feb_df = feb_df[(feb_df.duration >= 1) & (feb_df.duration <= 60)]\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "feb_df[categorical] = feb_df[categorical].astype(str)\n",
    "val_dicts = feb_df[categorical + numerical].to_dict(orient='records')\n",
    "# Use the same DictVectorizer that was fit on the training data\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "target = 'duration'\n",
    "feb_y_val = feb_df[target].values\n",
    "\n",
    "feb_y_pred = lr.predict(X_val)\n",
    "\n",
    "root_mean_squared_error(feb_y_val, feb_y_pred)"
   ],
   "id": "b564eee4a70d3995",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.8201754113565425"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Q6. Evaluating the model\n",
    "Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "Q: What's the RMSE on validation?\n",
    "\n",
    "A: 7.81\n"
   ],
   "id": "58b8dc6ca933f193"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
