{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "import tensorflow as tf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# function Hubert loss\n",
    "\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1.0\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "# example of using\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=huber_fn,\n",
    "    metrics=['mae']\n",
    ")"
   ],
   "id": "c033ec277b1bed86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create a custom loss class",
   "id": "a8d8ead10d892c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, delta=1.0, name=\"huber_loss\", *kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.delta = delta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \" this method is called during model training to compute the loss \"\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.delta\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.delta * (tf.abs(error) - self.delta / 2)\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        \" this method is necessary to serialize the loss function (save and load model) \"\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"delta\": self.delta}\n",
    "\n",
    "# example of using\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=HuberLoss(delta=1.0),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.save(\"my_model_with_huber_loss.keras\")\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\n",
    "    \"my_model_with_huber_loss.keras\",\n",
    "    custom_objects={\"HuberLoss\": HuberLoss} # <- necessary when loading a model with custom objects\n",
    ")"
   ],
   "id": "7fafae212c6525e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom Initializer, Regulazer, Constraint follow similar pattern",
   "id": "253720bf7d3dd542"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    sttdev = tf.sqrt(2.0 / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=sttdev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return 0.01 * tf.reduce_sum(tf.abs(weights))\n",
    "\n",
    "def my_positive_weights_constraint(weights):\n",
    "    return tf.where(weights < 0.0, tf.zeros_like(weights), weights)\n",
    "\n",
    "# example of using\n",
    "layer = tf.keras.layers.Dense(\n",
    "    units=64,\n",
    "    activation=my_softplus,\n",
    "    kernel_initializer=my_glorot_initializer,\n",
    "    kernel_regularizer=my_l1_regularizer,\n",
    "    kernel_constraint=my_positive_weights_constraint\n",
    ")\n",
    "\n",
    "# class for Regularizer\n",
    "\n",
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(self.factor * tf.abs(weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ],
   "id": "a9161b40f739f886"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom Metric",
   "id": "31c89e3a9daa7929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n",
    "\n",
    "class HuberMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ],
   "id": "d65f4584efffc10b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Special Layers",
   "id": "5289a208d314c0e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": tf.keras.activations.serialize(self.activation)}\n",
    "\n",
    "# Example of using\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=32),\n",
    "    MyDense(1)\n",
    "])"
   ],
   "id": "4f08c26c800719e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        Z = inputs\n",
    "\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "\n",
    "        result = inputs + Z\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    " class ResidualRegressor(tf.keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = tf.keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ],
   "id": "245a0ac244c6f20b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
