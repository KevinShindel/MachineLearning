{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-09T08:44:01.589518Z",
     "start_time": "2024-10-09T08:44:00.695788Z"
    }
   },
   "source": [
    "# Implement CustomTransformer\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:44:01.605333Z",
     "start_time": "2024-10-09T08:44:01.590630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load data \n",
    "train = pd.read_csv('../Kaggle/Challenges/data/titanic_train.csv') # training data\n",
    "test = pd.read_csv('../Kaggle/Challenges/data/titanic_test.csv') # test data"
   ],
   "id": "4a91ce120344088",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:44:02.084150Z",
     "start_time": "2024-10-09T08:44:02.078638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = train.drop('Survived', axis=1)\n",
    "y = train['Survived']"
   ],
   "id": "8a1bc8a9ac8fc359",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:44:02.709284Z",
     "start_time": "2024-10-09T08:44:02.702397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X, y, random_state=42, train_size=0.75)"
   ],
   "id": "7728df5cadad667e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:44:03.244817Z",
     "start_time": "2024-10-09T08:44:03.235443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    @staticmethod\n",
    "    def split_ticket(ticket: str) -> pd.Series:\n",
    "        \"\"\" Split Ticket with Destination and Ticket number \"\"\"\n",
    "        result = ['U', np.nan] # Default values\n",
    "        if ' ' in ticket: \n",
    "            # sometimes we have 2 spaces, we need split only by second space\n",
    "            if ticket.count(' ') > 1: # if there are more than 1 space (PC R 17757)\n",
    "                result = ticket.rsplit(' ', 1)\n",
    "            else:\n",
    "                result = ticket.split(' ') # split by space (PC 17757)\n",
    "        if ticket.isnumeric(): # if ticket is only numbers (12345)\n",
    "            result = ['U', ticket]\n",
    "        if ticket.isalpha(): # if ticket is only letters (LINE)\n",
    "            result = [ticket, np.nan]\n",
    "            \n",
    "        result[0] = result[0][0] # get first letter of Destination\n",
    "\n",
    "        return pd.Series(result)\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X,  y=None):\n",
    "        # Transformation logic\n",
    "\n",
    "        # Split Ticket with Destination and Ticket number\n",
    "        X[['Destination', 'TicketNumber']] = X['Ticket'].apply(self.split_ticket)\n",
    "\n",
    "        # Transform Destination into categorical\n",
    "        X['Destination'] = X['Destination'].astype('category').cat.codes\n",
    "\n",
    "        # Transform Cabin into Boolean\n",
    "        X['Cabin'] = X['Cabin'].notna()\n",
    "\n",
    "        # Cut Family Size into groups\n",
    "        family_group = ['Alone', 'Small', 'Middle', 'Big']\n",
    "        X['FamilySize'] = pd.cut(X['SibSp'] + X['Parch'] + 1, # Calculate Family Size\n",
    "                                         [0, 1, 4, 7, 11], # Define Family Size Groups\n",
    "                                         labels=family_group) # Assign Family Size Groups\n",
    "\n",
    "        X['FamilySize'] = X['FamilySize'].astype('category').cat.codes\n",
    "\n",
    "        return pd.DataFrame(X[self.columns], columns=self.columns)"
   ],
   "id": "1ac657234aa62804",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:44:09.674878Z",
     "start_time": "2024-10-09T08:44:05.823809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cust_cols = ['FamilySize', 'Destination', 'TicketNumber', 'Cabin', 'SibSp', 'Parch']\n",
    "pass_through = ['']\n",
    "\n",
    "cust_pipeline = Pipeline([                                        # This pipeline will fill missing numerical values with most frequent value\n",
    "    ('custom', CustomTransformer())\n",
    "])\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (cust_pipeline, cust_cols),\n",
    ")\n",
    "\n",
    "# col_transformer = ColumnTransformer(transformers=\n",
    "#     [\n",
    "#         ('cust_pipeline',cust_pipeline, cust_cols), # Check if columns are need ?\n",
    "#         ('passthrough', 'passthrough', pass_through)\n",
    "#     ],\n",
    "#     remainder='drop', n_jobs=-1\n",
    "# )\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train) # TODO: ValueError: A given column is not a column of the dataframe\n",
    "\n",
    "df = pd.DataFrame(X_train)"
   ],
   "id": "1f635b566d42d122",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Projects\\ML\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'FamilySize'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Projects\\ML\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:361\u001B[0m, in \u001B[0;36m_get_column_indices\u001B[1;34m(X, key)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m columns:\n\u001B[1;32m--> 361\u001B[0m     col_idx \u001B[38;5;241m=\u001B[39m \u001B[43mall_columns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    362\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col_idx, numbers\u001B[38;5;241m.\u001B[39mIntegral):\n",
      "File \u001B[1;32m~\\Projects\\ML\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'FamilySize'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 24\u001B[0m\n\u001B[0;32m     12\u001B[0m preprocessor \u001B[38;5;241m=\u001B[39m make_column_transformer(\n\u001B[0;32m     13\u001B[0m     (cust_pipeline, cust_cols),\n\u001B[0;32m     14\u001B[0m )\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# col_transformer = ColumnTransformer(transformers=\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m#     [\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#         ('cust_pipeline',cust_pipeline, cust_cols), # Check if columns are need ?\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#     remainder='drop', n_jobs=-1\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m X_train \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(X_train)\n",
      "File \u001B[1;32m~\\Projects\\ML\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 316\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    318\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    319\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    320\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    321\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    322\u001B[0m         )\n",
      "File \u001B[1;32m~\\Projects\\ML\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Projects\\ML\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:968\u001B[0m, in \u001B[0;36mColumnTransformer.fit_transform\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    965\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_transformers()\n\u001B[0;32m    966\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m _num_samples(X)\n\u001B[1;32m--> 968\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_column_callables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_remainder(X)\n\u001B[0;32m    971\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _routing_enabled():\n",
      "File \u001B[1;32m~\\Projects\\ML\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:536\u001B[0m, in \u001B[0;36mColumnTransformer._validate_column_callables\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    534\u001B[0m         columns \u001B[38;5;241m=\u001B[39m columns(X)\n\u001B[0;32m    535\u001B[0m     all_columns\u001B[38;5;241m.\u001B[39mappend(columns)\n\u001B[1;32m--> 536\u001B[0m     transformer_to_input_indices[name] \u001B[38;5;241m=\u001B[39m \u001B[43m_get_column_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_columns \u001B[38;5;241m=\u001B[39m all_columns\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transformer_to_input_indices \u001B[38;5;241m=\u001B[39m transformer_to_input_indices\n",
      "File \u001B[1;32m~\\Projects\\ML\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:369\u001B[0m, in \u001B[0;36m_get_column_indices\u001B[1;34m(X, key)\u001B[0m\n\u001B[0;32m    366\u001B[0m         column_indices\u001B[38;5;241m.\u001B[39mappend(col_idx)\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 369\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA given column is not a column of the dataframe\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    371\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m column_indices\n",
      "\u001B[1;31mValueError\u001B[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
