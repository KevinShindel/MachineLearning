{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dle_rl_qlearning.ipynb","provenance":[{"file_id":"1XiVYCbHUAWhqLPExUvnHPIk_lA7Sqp55","timestamp":1586376948529}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d940ac266dc64ad48e4a17a840f4975c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_154dd419dc6e472fbda39d80fd9ca4df","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3d0c677e81724bac8201613d69cdf851","IPY_MODEL_c5fb1a7d72894e09ba4c330f6a647f2a"]}},"154dd419dc6e472fbda39d80fd9ca4df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d0c677e81724bac8201613d69cdf851":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_601219036aec4b42a8095983c9f033af","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":5000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a66020d0f8dd405a8f31a20e5c0fbc0e"}},"c5fb1a7d72894e09ba4c330f6a647f2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4b8f6e2c6534b48925675c541972222","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5000/5000 [00:00&lt;00:00, 41796.75it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f80552934c4b4278bc61dff7fe8a37e9"}},"601219036aec4b42a8095983c9f033af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a66020d0f8dd405a8f31a20e5c0fbc0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4b8f6e2c6534b48925675c541972222":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f80552934c4b4278bc61dff7fe8a37e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70eec3f10d02453087a1626286c1c4bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ece8ab5280a4494da4290edf7dad1de2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_093c9f850d764aeb84eb2ab345e954f6","IPY_MODEL_4b2d6552031f4da496d7989e1fd2739a"]}},"ece8ab5280a4494da4290edf7dad1de2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"093c9f850d764aeb84eb2ab345e954f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9cfd9188fd2e4a439984b9a7d5b3a9ba","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":5000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af3d8369bc244412ac711c59ef1e9013"}},"4b2d6552031f4da496d7989e1fd2739a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1c9f17119d6d4f808c54108d241fed73","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5000/5000 [00:00&lt;00:00, 38942.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e47a56f51f6455daa639ca1583320a3"}},"9cfd9188fd2e4a439984b9a7d5b3a9ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"af3d8369bc244412ac711c59ef1e9013":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c9f17119d6d4f808c54108d241fed73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e47a56f51f6455daa639ca1583320a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"V3aiTZxj8ijt","colab_type":"text"},"source":["In this notebook, we'll implement the standard Q-learning technique using pure Python."]},{"cell_type":"code","metadata":{"id":"jwiZsgSIAT34","colab_type":"code","colab":{}},"source":["from random import random, randint, choice\n","from tqdm.auto import tqdm\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X4hFstNh8q_b","colab_type":"text"},"source":["The function below trains an agent using Q learning given a transition and reward matrix, both with size `(Nr. of States, Nr. of Actions)`, using `None` values for transitions which are not allowed."]},{"cell_type":"code","metadata":{"id":"aK7PAuz6hsvt","colab_type":"code","colab":{}},"source":["def train_agent(transition_matrix, reward_matrix, \n","        valid_initial_states=None, \n","        end_states=None,\n","        gamma=0.8, alpha=1, epsilon=0, episodes=5000):\n","\n","  nr_states  = len(transition_matrix)\n","  nr_actions = len(transition_matrix[0])\n","  Q = [[0.0 for a in range(nr_actions)] for s in range(nr_states)]\n","\n","  if valid_initial_states is None:\n","    # By default, all states are valid initial states\n","    valid_initial_states = range(nr_states)\n","\n","  if end_states is None:\n","    # No end states, so we will infer end states from the transition matrix\n","    end_states = []\n","\n","  for episode in tqdm(range(episodes)):\n","    # Select a random initial state\n","    state = choice(valid_initial_states)\n","\n","    # While the goal state hasn't been reached\n","    while state not in end_states:\n","      possible_actions_in_current_state = [a for a in range(nr_actions) if transition_matrix[state][a] is not None]\n","      if not len(possible_actions_in_current_state):\n","        # Nothing else we can do here\n","        break\n","\n","      if random() < epsilon:        # Explore: pick an action at random\n","        action = choice(possible_actions_in_current_state)\n","      else:                         # Exploit: pick an action based on the Q matrix\n","        best_Q = max([Q[state][a] for a in possible_actions_in_current_state])\n","        best_actions = [a for a in possible_actions_in_current_state if Q[state][a] == best_Q]\n","        action = choice(best_actions)\n","      \n","      next_state = transition_matrix[state][action]\n","      possible_actions_in_next_state = [a for a in range(nr_actions) if transition_matrix[next_state][a] is not None]\n","      \n","      if not len(possible_actions_in_next_state):\n","        # Nothing else we can do there\n","        break\n","\n","      # Get maximum Q value for this next state based on all possible actions\n","      best_Q_in_next_state = max([Q[next_state][a] for a in possible_actions_in_next_state])\n","      \n","      # Update Q and set next state as current one\n","      Q[state][action] = Q[state][action] + alpha * (reward_matrix[state][action] + gamma * best_Q_in_next_state - Q[state][action])\n","\n","      # And move on the the next state\n","      state = next_state\n","\n","  return Q"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EeSFIlcf9VIs","colab_type":"text"},"source":["Let's now use this function based on the example provided. First, we define the topology of our maze using a list of bidirectional arcs:"]},{"cell_type":"code","metadata":{"id":"AbxZEv7dhsvx","colab_type":"code","colab":{}},"source":["arcs = [(0,1), (0,3), (1,2), (1,4), (2,5), (4,3), (3,6), (4,7)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dUVV2dRb9rp7","colab_type":"text"},"source":["From this, we derive our states and actions:"]},{"cell_type":"code","metadata":{"id":"1mEDLEoZhsvz","colab_type":"code","colab":{}},"source":["states  = list(set([x for v in arcs for x in v]))\n","actions = states[:]\n","goal    = 7\n","\n","transition_matrix = [\n","\t[None if (i,j) not in arcs and (j,i) not in arcs else j for j in actions]\n","\tfor i in states\n","]\n","\n","reward_matrix = [\n","\t[None if (i,j) not in arcs and (j,i) not in arcs else 100 if j == goal else 0 for j in actions]\n","\tfor i in states\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rmZ_O755-Byz","colab_type":"code","colab":{}},"source":["def mprint(matrix):\n","  for row in matrix:\n","    print(' , '.join(\n","        ['{: >6}'.format(np.round(item, 1) if item is not None else ' ') for item in row]\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j470g4D09z-7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1595329832288,"user_tz":-120,"elapsed":970,"user":{"displayName":"Seppe vanden Broucke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMpesh_oeuo7Fc2WsgK89OJRIeyn_p5F2LV-ineDc=s64","userId":"09380512084218149317"}},"outputId":"c37c1199-73e8-4b27-e707-1062568317b2"},"source":["print(\"The transition matrix:\")\n","mprint(transition_matrix)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The transition matrix:\n","       ,      1 ,        ,      3 ,        ,        ,        ,       \n","     0 ,        ,      2 ,        ,      4 ,        ,        ,       \n","       ,      1 ,        ,        ,        ,      5 ,        ,       \n","     0 ,        ,        ,        ,      4 ,        ,      6 ,       \n","       ,      1 ,        ,      3 ,        ,        ,        ,      7\n","       ,        ,      2 ,        ,        ,        ,        ,       \n","       ,        ,        ,      3 ,        ,        ,        ,       \n","       ,        ,        ,        ,      4 ,        ,        ,       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T2pKoiRSCelF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1595329902466,"user_tz":-120,"elapsed":1011,"user":{"displayName":"Seppe vanden Broucke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMpesh_oeuo7Fc2WsgK89OJRIeyn_p5F2LV-ineDc=s64","userId":"09380512084218149317"}},"outputId":"12aa17b8-312d-4408-b358-733516a42e9f"},"source":["print(\"The reward matrix:\")\n","mprint(reward_matrix)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The reward matrix:\n","       ,      0 ,        ,      0 ,        ,        ,        ,       \n","     0 ,        ,      0 ,        ,      0 ,        ,        ,       \n","       ,      0 ,        ,        ,        ,      0 ,        ,       \n","     0 ,        ,        ,        ,      0 ,        ,      0 ,       \n","       ,      0 ,        ,      0 ,        ,        ,        ,    100\n","       ,        ,      0 ,        ,        ,        ,        ,       \n","       ,        ,        ,      0 ,        ,        ,        ,       \n","       ,        ,        ,        ,      0 ,        ,        ,       \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JiUTuyoF--ZU","colab_type":"text"},"source":["First, we'll train an agent which does no exploration at all (`epsilon` = 0):"]},{"cell_type":"code","metadata":{"id":"wl5adA2Lhsv4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":239,"referenced_widgets":["d940ac266dc64ad48e4a17a840f4975c","154dd419dc6e472fbda39d80fd9ca4df","3d0c677e81724bac8201613d69cdf851","c5fb1a7d72894e09ba4c330f6a647f2a","601219036aec4b42a8095983c9f033af","a66020d0f8dd405a8f31a20e5c0fbc0e","a4b8f6e2c6534b48925675c541972222","f80552934c4b4278bc61dff7fe8a37e9"]},"executionInfo":{"status":"ok","timestamp":1595329907210,"user_tz":-120,"elapsed":867,"user":{"displayName":"Seppe vanden Broucke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMpesh_oeuo7Fc2WsgK89OJRIeyn_p5F2LV-ineDc=s64","userId":"09380512084218149317"}},"outputId":"57304995-33e4-40bd-f728-b8a832cfaf05"},"source":["Q = train_agent(transition_matrix, reward_matrix, end_states=[goal], gamma=0.8, alpha=1, epsilon=0)\n","print(\"\\nThe trained Q matrix:\")\n","mprint(Q)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d940ac266dc64ad48e4a17a840f4975c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","The trained Q matrix:\n","   0.0 ,    0.0 ,    0.0 ,   64.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n","  51.2 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n","   0.0 ,   41.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n","   0.0 ,    0.0 ,    0.0 ,    0.0 ,   80.0 ,    0.0 ,    0.0 ,    0.0\n","   0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,  100.0\n","   0.0 ,    0.0 ,   32.8 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n","   0.0 ,    0.0 ,    0.0 ,   64.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n","   0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ByD4tiQmAgt6","colab_type":"text"},"source":["Now, we will use an exploration factor:"]},{"cell_type":"code","metadata":{"id":"I9ajCp7xrea7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":239,"referenced_widgets":["70eec3f10d02453087a1626286c1c4bf","ece8ab5280a4494da4290edf7dad1de2","093c9f850d764aeb84eb2ab345e954f6","4b2d6552031f4da496d7989e1fd2739a","9cfd9188fd2e4a439984b9a7d5b3a9ba","af3d8369bc244412ac711c59ef1e9013","1c9f17119d6d4f808c54108d241fed73","5e47a56f51f6455daa639ca1583320a3"]},"executionInfo":{"status":"ok","timestamp":1595329915244,"user_tz":-120,"elapsed":882,"user":{"displayName":"Seppe vanden Broucke","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMpesh_oeuo7Fc2WsgK89OJRIeyn_p5F2LV-ineDc=s64","userId":"09380512084218149317"}},"outputId":"dc321310-9276-4fe0-d273-1f1a6c93e475"},"source":["Q = train_agent(transition_matrix, reward_matrix, end_states=[goal], gamma=0.8, alpha=1, epsilon=0.3)\n","print(\"\\nThe trained Q matrix:\")\n","mprint(Q)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70eec3f10d02453087a1626286c1c4bf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","The trained Q matrix:\n","   0.0 ,   64.0 ,    0.0 ,   64.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n","  51.2 ,    0.0 ,   51.2 ,    0.0 ,   80.0 ,    0.0 ,    0.0 ,    0.0\n","   0.0 ,   64.0 ,    0.0 ,    0.0 ,    0.0 ,   41.0 ,    0.0 ,    0.0\n","  51.2 ,    0.0 ,    0.0 ,    0.0 ,   80.0 ,    0.0 ,   51.2 ,    0.0\n","   0.0 ,   64.0 ,    0.0 ,   64.0 ,    0.0 ,    0.0 ,    0.0 ,  100.0\n","   0.0 ,    0.0 ,   51.2 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n","   0.0 ,    0.0 ,    0.0 ,   64.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n","   0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0 ,    0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mT_YRHUgAmCq","colab_type":"text"},"source":["Which differences do you see? In particular, take a look at the Q-values for the first row."]},{"cell_type":"code","metadata":{"id":"OZkHhtc8B4LC","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}