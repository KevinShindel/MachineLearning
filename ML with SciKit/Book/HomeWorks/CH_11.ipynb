{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries",
   "id": "56449ddada0a43c4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-30T20:28:12.078051Z",
     "start_time": "2025-11-30T20:28:12.072627Z"
    }
   },
   "source": [
    "from tensorflow.keras import layers, initializers, callbacks, models, optimizers, activations, backend, losses, metrics, regularizers\n",
    "from tensorflow.keras.wrappers import SKLearnRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import make_regression\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import tensorflow as tf\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create dataset",
   "id": "e2fc7c32b1502b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X, y = make_regression(n_samples=100000,\n",
    "                                     n_features=10,\n",
    "                                     n_informative=4,\n",
    "                                     noise=0.1,\n",
    "                                     random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "fd6aa1f63c152501",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define Exponential Learning Rate Callback",
   "id": "d78f5b56e8e2c611"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ExponentialLearningRate(callbacks.Callback):\n",
    "\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        # get current LR\n",
    "        lr = backend.get_value(self.model.optimizer.learning_rate)\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs.get(\"loss\"))\n",
    "        # compute new LR\n",
    "        new_lr = lr * self.factor\n",
    "        # set new LR (works with modern Keras)\n",
    "        self.model.optimizer.learning_rate.assign(new_lr)"
   ],
   "id": "c5460ddf86fdb2e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set up logging and callbacks",
   "id": "5acc9c74f9f384e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_index = 1  # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"regressor_logs\", \"run_{:03d}\".format(run_index))\n",
    "\n",
    "tensorboard_cb = callbacks.TensorBoard(run_logdir)"
   ],
   "id": "798405861b4c8424",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "early_stop = callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ],
   "id": "b37bc0aca4b49932",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build and train model (DNN Regressor)",
   "id": "cb36a37ee50f4e7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_model(X, y, n_hidden=1, n_neurons=30, learning_rate=0.0001):\n",
    "    input_shape = X.shape[1:]\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=input_shape))\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(layers.Dense(units=n_neurons,\n",
    "                               activation=activations.relu,\n",
    "                               kernel_initializer=initializers.HeNormal()))\n",
    "    model.add(layers.Dense(units=1))\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=losses.mse,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[metrics.mse, metrics.mae, metrics.mape, metrics.huber])\n",
    "    return model"
   ],
   "id": "6920d16227d7b0b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "estimator = SKLearnRegressor(model=build_model)",
   "id": "cb716d5f85dd2a12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = estimator.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=1,\n",
    "                        validation_data=(X_valid, y_valid),\n",
    "                        callbacks=[\n",
    "                            early_stop,\n",
    "                            expon_lr,\n",
    "\n",
    "                        ],\n",
    "                        verbose=2)"
   ],
   "id": "6e0d71784cbf0fe4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analyze LR-finder results",
   "id": "8e044135e2eed57e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "idx = np.argmin(expon_lr.losses)\n",
    "best_lr_sweep = expon_lr.rates[idx] / 10\n",
    "print(\"LR-finder min loss lr:\", best_lr_sweep)\n",
    "print(\"loss at that lr:\", expon_lr.losses[idx])\n",
    "print(\"min/max lr in sweep:\", min(expon_lr.rates), max(expon_lr.rates))\n",
    "\n",
    "smoothed = gaussian_filter1d(expon_lr.losses, sigma=2)\n",
    "\n",
    "plt.plot(expon_lr.rates, expon_lr.losses, alpha=0.3, label='batch loss')\n",
    "plt.plot(expon_lr.rates, smoothed, label='smoothed loss')\n",
    "plt.xscale('log')\n",
    "plt.scatter([best_lr_sweep], [expon_lr.losses[idx]], color='red', label=f'best lr {best_lr_sweep:.2e}')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ],
   "id": "c2a43007828ac86c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter tuning with Randomized Search CV on DNN Regressor",
   "id": "7973af10e6023f1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    \"model_kwargs\": [\n",
    "        {\"n_hidden\": h, \"n_neurons\": n, \"learning_rate\": lr}\n",
    "        for h in [1, 2, 3, 4]\n",
    "        for n in [16, 32, 64, 128]\n",
    "        for lr in [0.03, 0.003, 0.0003]\n",
    "    ]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(estimator,\n",
    "                            param_distributions=param_grid,\n",
    "                            n_iter=10,\n",
    "                            cv=3,\n",
    "                            scoring=\"\"\n",
    "                                    \"\",\n",
    "                            verbose=2)\n",
    "\n",
    "search.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stop], verbose=0)"
   ],
   "id": "53c75ac16c003272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model = search.best_estimator_\n",
    "best_params = search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ],
   "id": "bf4e45276aa841e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_params = {'model_kwargs': {'n_hidden': 2, 'n_neurons': 128, 'learning_rate': 0.044}}",
   "id": "235984eaa3eb60a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred= best_model.predict(X_valid)\n",
    "mse = ((y_valid - y_pred.flatten()) ** 2).mean()\n",
    "print(\"Best model MSE on validation set:\", mse)"
   ],
   "id": "40783cc6685baf26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create a final model with the best hyperparameters and train it",
   "id": "68306e4d8cb2ee77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "estimator = SKLearnRegressor(model=build_model, **best_params)",
   "id": "6adcc9686620ad92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = estimator.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=100,\n",
    "                        validation_data=(X_valid, y_valid),\n",
    "                        callbacks=[\n",
    "                            early_stop,\n",
    "                            tensorboard_cb\n",
    "                        ],\n",
    "                        verbose=2)"
   ],
   "id": "a1a3dc2beddf04a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # CIFAR10 Image Classification with DNN Classifier",
   "id": "2e48c7bac765d5b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. DNN with 20 hidden layers, each with 100 neurons, ReLU activation, He initialization.\n",
    "2. Use Nadam and EarlyStopping with patience of 5 epochs.\n",
    "3. Add BatchNormalization after each hidden layer. ( compare results with and without BatchNorm)\n",
    "4. Change to SELU + Lecun Normal initialization. ( compare results with and without BatchNorm)\n",
    "5. Add AlfaDropout with rate 0.1 after each hidden layer. ( compare results with and without BatchNorm)\n",
    "6. Train model with LR found by LR-finder."
   ],
   "id": "895c7848811c3b00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:27:41.546448Z",
     "start_time": "2025-11-30T20:27:33.859592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ],
   "id": "830d11adab52b6c4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:27:46.371155Z",
     "start_time": "2025-11-30T20:27:41.570652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds"
   ],
   "id": "20b54d8aa16fb4e1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train[:1].shape",
   "id": "7d849994c5c6128",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. DNN with 20 hidden layers, each with 100 neurons, ReLU activation, He initialization.",
   "id": "d7cbba8ba97423b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.InputLayer(shape=(32, 32, 3)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "for i in range(20):\n",
    "    model.add(layers.Dense(units=100,\n",
    "                           activation=activations.elu,\n",
    "                           kernel_initializer=initializers.he_normal))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation=activations.softmax))"
   ],
   "id": "55b4456482e09c9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Use Nadam and EarlyStopping with patience of 5 epochs.",
   "id": "801da0f18a5b9ad4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.compile(loss=losses.sparse_categorical_crossentropy,\n",
    "              optimizer=optimizers.Nadam(learning_rate=5e-5),\n",
    "              metrics=['accuracy'])"
   ],
   "id": "8e9a59151b53d1ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "early_stopping_cb = callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "    \"cifar10_dnn_model.keras\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "run_idx = 3\n",
    "log_dir = os.path.join(os.curdir, \"cifar10_dnn_logs\", \"run_{:03d}\".format(run_idx))\n",
    "\n",
    "tensor_board_cb = callbacks.TensorBoard(\n",
    "    log_dir=log_dir\n",
    ")"
   ],
   "id": "2b8cb54e31eb5ea8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./cifar10_dnn_logs --port=6006"
   ],
   "id": "b7bd23a946ba3d0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "    early_stopping_cb,\n",
    "    model_checkpoint_cb,\n",
    "    tensor_board_cb\n",
    "]\n",
    ")\n",
    "# Epoch 20/50 1563/1563 ━━━━━━━━━━━━━━━━━━━━ 21s 14ms/step - accuracy: 0.5684 - loss: 1.2049 - val_accuracy: 0.4993 - val_loss: 1.4410"
   ],
   "id": "b8dc1960ecc98081",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = models.load_model(\"cifar10_dnn_model.keras\")\n",
    "model.evaluate(X_valid, y_valid)"
   ],
   "id": "579bb1b607d36dcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T17:49:02.406375Z",
     "start_time": "2025-11-30T17:43:15.539045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(shape=(32,32,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(layers.Dense(100, kernel_initializer=initializers.he_normal))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation(activations.elu))\n",
    "\n",
    "model.add(layers.Dense(10, activation=activations.softmax))\n",
    "\n",
    "model.compile(loss=losses.sparse_categorical_crossentropy,\n",
    "              optimizer=optimizers.Nadam(learning_rate=5e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "    \"cifar10_dnn_model.keras\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "run_idx = 4\n",
    "log_dir = os.path.join(os.curdir, \"cifar10_dnn_logs\", \"run_{:03d}\".format(run_idx))\n",
    "\n",
    "tensor_board_cb = callbacks.TensorBoard(\n",
    "    log_dir=log_dir\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "    early_stopping_cb,\n",
    "    model_checkpoint_cb,\n",
    "    tensor_board_cb\n",
    "]\n",
    ")\n",
    "# Epoch 10/100 1563/1563 ━━━━━━━━━━━━━━━━━━━━ 31s 20ms/step - accuracy: 0.5768 - loss: 1.2098 - val_accuracy: 0.4542 - val_loss: 1.6075"
   ],
   "id": "9fd92ba28361bcba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\username\\Projects\\MachineLearning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m57s\u001B[0m 21ms/step - accuracy: 0.3463 - loss: 1.8284 - val_accuracy: 0.4190 - val_loss: 1.6300\n",
      "Epoch 2/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 21ms/step - accuracy: 0.4126 - loss: 1.6533 - val_accuracy: 0.4361 - val_loss: 1.5754\n",
      "Epoch 3/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 20ms/step - accuracy: 0.4450 - loss: 1.5708 - val_accuracy: 0.4546 - val_loss: 1.5437\n",
      "Epoch 4/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 22ms/step - accuracy: 0.4689 - loss: 1.5060 - val_accuracy: 0.4648 - val_loss: 1.5254\n",
      "Epoch 5/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 21ms/step - accuracy: 0.4908 - loss: 1.4461 - val_accuracy: 0.4639 - val_loss: 1.5179\n",
      "Epoch 6/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 22ms/step - accuracy: 0.5118 - loss: 1.3905 - val_accuracy: 0.4587 - val_loss: 1.5351\n",
      "Epoch 7/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 19ms/step - accuracy: 0.5302 - loss: 1.3413 - val_accuracy: 0.4609 - val_loss: 1.5470\n",
      "Epoch 8/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 19ms/step - accuracy: 0.5461 - loss: 1.2947 - val_accuracy: 0.4619 - val_loss: 1.5599\n",
      "Epoch 9/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 20ms/step - accuracy: 0.5623 - loss: 1.2497 - val_accuracy: 0.4585 - val_loss: 1.5815\n",
      "Epoch 10/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 20ms/step - accuracy: 0.5768 - loss: 1.2098 - val_accuracy: 0.4542 - val_loss: 1.6075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a3864c56a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Change to SELU + Lecun Normal initialization. ( compare results with and without BatchNorm)",
   "id": "86ccec7afac9cee1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T18:25:14.023612Z",
     "start_time": "2025-11-30T18:13:58.652454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(shape=(32,32,3)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(layers.Dense(100,\n",
    "                                 kernel_initializer=initializers.lecun_normal,\n",
    "                                 activation=activations.selu))\n",
    "\n",
    "model.add(layers.Dense(10, activation=activations.softmax))\n",
    "\n",
    "model.compile(loss=losses.sparse_categorical_crossentropy,\n",
    "              optimizer=optimizers.Nadam(learning_rate=7e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "    \"cifar10_dnn_model.keras\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "run_idx = 6\n",
    "log_dir = os.path.join(os.curdir, \"cifar10_dnn_logs\", \"run_{:03d}\".format(run_idx))\n",
    "\n",
    "tensor_board_cb = callbacks.TensorBoard(\n",
    "    log_dir=log_dir\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_test_scaled, y_test),\n",
    "          callbacks=[\n",
    "    early_stopping_cb,\n",
    "    model_checkpoint_cb,\n",
    "    tensor_board_cb\n",
    "])\n",
    "# Epoch 31/100 1563/1563 ━━━━━━━━━━━━━━━━━━━━ 21s 13ms/step - accuracy: 0.6309 - loss: 1.0734 - val_accuracy: 0.4968 - val_loss: 1.5833"
   ],
   "id": "a8c307738b37b105",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 15ms/step - accuracy: 0.3151 - loss: 1.9074 - val_accuracy: 0.3757 - val_loss: 1.7227\n",
      "Epoch 2/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 14ms/step - accuracy: 0.3979 - loss: 1.6941 - val_accuracy: 0.4339 - val_loss: 1.5937\n",
      "Epoch 3/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 14ms/step - accuracy: 0.4307 - loss: 1.6036 - val_accuracy: 0.4506 - val_loss: 1.5781\n",
      "Epoch 4/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.4606 - loss: 1.5321 - val_accuracy: 0.4550 - val_loss: 1.5408\n",
      "Epoch 5/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.4794 - loss: 1.4790 - val_accuracy: 0.4609 - val_loss: 1.5449\n",
      "Epoch 6/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.4996 - loss: 1.4270 - val_accuracy: 0.4784 - val_loss: 1.5082\n",
      "Epoch 7/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.5145 - loss: 1.3827 - val_accuracy: 0.4898 - val_loss: 1.5040\n",
      "Epoch 8/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.5349 - loss: 1.3424 - val_accuracy: 0.4759 - val_loss: 1.5069\n",
      "Epoch 9/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.5438 - loss: 1.3131 - val_accuracy: 0.4837 - val_loss: 1.5157\n",
      "Epoch 10/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 14ms/step - accuracy: 0.5540 - loss: 1.2864 - val_accuracy: 0.4953 - val_loss: 1.4815\n",
      "Epoch 11/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.5651 - loss: 1.2583 - val_accuracy: 0.4879 - val_loss: 1.4763\n",
      "Epoch 12/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.5734 - loss: 1.2356 - val_accuracy: 0.4902 - val_loss: 1.4906\n",
      "Epoch 13/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.5858 - loss: 1.2065 - val_accuracy: 0.5003 - val_loss: 1.4894\n",
      "Epoch 14/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 14ms/step - accuracy: 0.5913 - loss: 1.1889 - val_accuracy: 0.4949 - val_loss: 1.5067\n",
      "Epoch 15/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.5998 - loss: 1.1717 - val_accuracy: 0.4999 - val_loss: 1.5179\n",
      "Epoch 16/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.6092 - loss: 1.1496 - val_accuracy: 0.5070 - val_loss: 1.4951\n",
      "Epoch 17/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.6143 - loss: 1.1272 - val_accuracy: 0.4940 - val_loss: 1.5566\n",
      "Epoch 18/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.6208 - loss: 1.1153 - val_accuracy: 0.4946 - val_loss: 1.5184\n",
      "Epoch 19/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.6285 - loss: 1.0923 - val_accuracy: 0.4956 - val_loss: 1.5355\n",
      "Epoch 20/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.6341 - loss: 1.0843 - val_accuracy: 0.5033 - val_loss: 1.5463\n",
      "Epoch 21/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.6412 - loss: 1.0624 - val_accuracy: 0.5015 - val_loss: 1.5805\n",
      "Epoch 22/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.4866 - loss: 45.9606 - val_accuracy: 0.4121 - val_loss: 1.6662\n",
      "Epoch 23/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.5039 - loss: 1.3979 - val_accuracy: 0.4528 - val_loss: 1.5877\n",
      "Epoch 24/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 14ms/step - accuracy: 0.5461 - loss: 1.2984 - val_accuracy: 0.4740 - val_loss: 1.5454\n",
      "Epoch 25/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.5724 - loss: 1.2314 - val_accuracy: 0.4757 - val_loss: 1.5504\n",
      "Epoch 26/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.5866 - loss: 1.1923 - val_accuracy: 0.4869 - val_loss: 1.5386\n",
      "Epoch 27/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.5985 - loss: 1.1593 - val_accuracy: 0.4900 - val_loss: 1.5524\n",
      "Epoch 28/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.6074 - loss: 1.1334 - val_accuracy: 0.4972 - val_loss: 1.5731\n",
      "Epoch 29/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.6173 - loss: 1.1126 - val_accuracy: 0.4967 - val_loss: 1.5616\n",
      "Epoch 30/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 14ms/step - accuracy: 0.6253 - loss: 1.0947 - val_accuracy: 0.4936 - val_loss: 1.5904\n",
      "Epoch 31/100\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 13ms/step - accuracy: 0.6309 - loss: 1.0734 - val_accuracy: 0.4968 - val_loss: 1.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a3865e7360>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Add AlfaDropout with rate 0.1 after each hidden layer. ( compare results with and without BatchNorm)",
   "id": "1952acd1b3103ca6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T18:38:08.762522Z",
     "start_time": "2025-11-30T18:38:08.753597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MCAlphaDropout(layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "mc_model = models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])\n",
    "\n",
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)\n",
    "\n"
   ],
   "id": "96e539e592a7787d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T18:39:05.107906Z",
     "start_time": "2025-11-30T18:38:44.987606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_test_scaled)\n",
    "accuracy = np.mean(y_pred == y_test[:, 0])\n",
    "accuracy"
   ],
   "id": "ec4b91a9f54e7286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.4879)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Train model with LR found by LR-finder",
   "id": "8b90993110f92763"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T18:41:24.871920Z",
     "start_time": "2025-11-30T18:41:24.083889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(shape=(32,32,3)))\n",
    "model.add(layers.Flatten())\n",
    "for _ in range(20):\n",
    "    model.add(layers.Dense(100, kernel_initializer=initializers.lecun_normal, activation=activations.selu))\n",
    "\n",
    "model.add(layers.AlphaDropout(rate=0.1))\n",
    "model.add(layers.Dense(10, activation=activations.softmax))\n",
    "\n",
    "model.compile(loss=losses.sparse_categorical_crossentropy,\n",
    "              optimizer=optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])"
   ],
   "id": "658bed9a69bad093",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1Cycle scheduling",
   "id": "e9fa293d280a6942"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:50:39.379349Z",
     "start_time": "2025-11-30T19:50:39.367995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "class ExponentialLearningRate(callbacks.Callback):\n",
    "\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        # get current LR\n",
    "        lr = backend.get_value(self.model.optimizer.learning_rate)\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs.get(\"loss\"))\n",
    "        # compute new LR\n",
    "        new_lr = lr * self.factor\n",
    "        # set new LR (works with modern Keras)\n",
    "        self.model.optimizer.learning_rate.assign(new_lr)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=1e-5, max_rate=10.0):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "\n",
    "    lr_var = model.optimizer.learning_rate\n",
    "    init_lr = float(lr_var.numpy())\n",
    "    lr_var.assign(min_rate)\n",
    "\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=[exp_lr])\n",
    "\n",
    "    lr_var.assign(init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis((min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2))\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ],
   "id": "57b238bcaa6ad2b4",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:59:26.402055Z",
     "start_time": "2025-11-30T19:59:26.283048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(shape=(32,32,3)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ],
   "id": "8272f0700dc9c1cf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:50:50.683953Z",
     "start_time": "2025-11-30T19:50:42.737057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)\n",
    "plt.axis((min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4))"
   ],
   "id": "400eedd2a8f23957",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m391/391\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 16ms/step - accuracy: 0.1799 - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(9.999999747378752e-06),\n",
       " np.float64(9.652833938598633),\n",
       " np.float64(2.4113738536834717),\n",
       " np.float64(3.6479352201734274))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:00:53.500986Z",
     "start_time": "2025-11-30T20:00:53.491442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class OneCycleScheduler(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Keras callback implementing the 1‑cycle learning rate policy.\n",
    "\n",
    "    The schedule is split into three phases over a fixed number of iterations\n",
    "    (batches):\n",
    "    1. Warm‑up: learning rate increases linearly from `start_rate` to `max_rate`.\n",
    "    2. Cool‑down: learning rate decreases linearly from `max_rate` back to\n",
    "       `start_rate`.\n",
    "    3. Final annealing: learning rate decreases linearly from `start_rate` to\n",
    "       `last_rate` during the last `last_iterations` steps.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    iterations : int\n",
    "        Total number of training iterations (batches) over which the 1‑cycle\n",
    "        schedule is applied. Typically:\n",
    "        `iterations = ceil(num_samples / batch_size) * num_epochs`.\n",
    "    max_rate : float\n",
    "        Maximum learning rate reached during the cycle.\n",
    "    start_rate : Optional[float], default=None\n",
    "        Initial learning rate. If `None`, it is set to `max_rate / 10`.\n",
    "    last_iterations : Optional[int], default=None\n",
    "        Number of iterations in the final annealing phase.\n",
    "        If `None`, it is set to `iterations // 10 + 1`.\n",
    "    last_rate : Optional[float], default=None\n",
    "        Final learning rate at the end of training.\n",
    "        If `None`, it is set to `start_rate / 1000`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    iterations : int\n",
    "        Total number of iterations in the schedule.\n",
    "    max_rate : float\n",
    "        Maximum learning rate in the schedule.\n",
    "    start_rate : float\n",
    "        Starting learning rate.\n",
    "    last_iterations : int\n",
    "        Number of iterations used for the final annealing phase.\n",
    "    half_iteration : int\n",
    "        Number of iterations in each of the first two phases\n",
    "        (warm‑up and cool‑down).\n",
    "    last_rate : float\n",
    "        Final learning rate value.\n",
    "    iteration : int\n",
    "        Counter of how many iterations (batches) have been processed.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This callback updates `model.optimizer.learning_rate` on each batch.\n",
    "    It supports both `tf.Variable` learning rates (via `assign`) and plain\n",
    "    Python/float learning rates (via attribute assignment).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        iterations: int,\n",
    "        max_rate: float,\n",
    "        start_rate: Optional[float] = None,\n",
    "        last_iterations: Optional[int] = None,\n",
    "        last_rate: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.iterations: int = iterations\n",
    "        self.max_rate: float = max_rate\n",
    "        self.start_rate: float = start_rate if start_rate is not None else max_rate / 10.0\n",
    "        self.last_iterations: int = last_iterations if last_iterations is not None else iterations // 10 + 1\n",
    "        self.half_iteration: int = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate: float = last_rate if last_rate is not None else self.start_rate / 1000.0\n",
    "        self.iteration: int = 0\n",
    "\n",
    "    def _interpolate(self, iter1: int, iter2: int, rate1: float, rate2: float) -> float:\n",
    "        \"\"\"\n",
    "        Linearly interpolate a learning rate between two iterations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        iter1 : int\n",
    "            Start iteration of the interval.\n",
    "        iter2 : int\n",
    "            End iteration of the interval.\n",
    "        rate1 : float\n",
    "            Learning rate at `iter1`.\n",
    "        rate2 : float\n",
    "            Learning rate at `iter2`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Interpolated learning rate for the current `self.iteration`.\n",
    "        \"\"\"\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1) / (iter2 - iter1)) + rate1\n",
    "\n",
    "    def on_batch_begin(self, batch: int, logs: Optional[dict] = None) -> None:\n",
    "        \"\"\"\n",
    "        Update the optimizer learning rate at the beginning of each batch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : int\n",
    "            Index of the current batch within the epoch.\n",
    "        logs : Optional[dict], default=None\n",
    "            Dictionary of logs; not used but kept for API compatibility.\n",
    "        \"\"\"\n",
    "        if self.iteration < self.half_iteration:\n",
    "            # Warm‑up phase\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            # Cool‑down phase\n",
    "            rate = self._interpolate(\n",
    "                self.half_iteration,\n",
    "                2 * self.half_iteration,\n",
    "                self.max_rate,\n",
    "                self.start_rate,\n",
    "            )\n",
    "        else:\n",
    "            # Final annealing phase\n",
    "            rate = self._interpolate(\n",
    "                2 * self.half_iteration,\n",
    "                self.iterations,\n",
    "                self.start_rate,\n",
    "                self.last_rate,\n",
    "            )\n",
    "\n",
    "        self.iteration += 1\n",
    "\n",
    "        lr = self.model.optimizer.learning_rate  # type: ignore[attr-defined]\n",
    "        if hasattr(lr, \"assign\"):\n",
    "            lr.assign(rate)\n",
    "        else:\n",
    "            self.model.optimizer.learning_rate = rate  # type: ignore[assignment]\n"
   ],
   "id": "def6dfec14b00f06",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T20:21:59.172863Z",
     "start_time": "2025-11-30T20:18:55.925141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs, max_rate=0.05)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    epochs=n_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test_scaled, y_test),\n",
    "                    callbacks=[onecycle],\n",
    "                    verbose=2)\n",
    "\n",
    "# One cycle allowed us to train the model in just 15 epochs, each taking only 2 seconds (thanks to the larger batch size).\n",
    "# This is several times faster than the fastest model we trained so far.\n",
    "# Moreover, we improved the model's performance (from 47.6% to 52.0%).\n",
    "# The batch normalized model reaches a slightly better performance (54%), but it's much slower to train."
   ],
   "id": "1ea5effbb99ae1f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "391/391 - 7s - 17ms/step - accuracy: 0.8223 - loss: 0.5601 - val_accuracy: 0.5155 - val_loss: 1.5992\n",
      "Epoch 2/25\n",
      "391/391 - 6s - 16ms/step - accuracy: 0.8186 - loss: 0.5672 - val_accuracy: 0.5118 - val_loss: 1.6523\n",
      "Epoch 3/25\n",
      "391/391 - 6s - 15ms/step - accuracy: 0.8151 - loss: 0.5732 - val_accuracy: 0.5116 - val_loss: 1.7128\n",
      "Epoch 4/25\n",
      "391/391 - 7s - 17ms/step - accuracy: 0.8096 - loss: 0.5837 - val_accuracy: 0.5063 - val_loss: 1.7916\n",
      "Epoch 5/25\n",
      "391/391 - 9s - 24ms/step - accuracy: 0.7989 - loss: 0.6033 - val_accuracy: 0.4986 - val_loss: 1.8841\n",
      "Epoch 6/25\n",
      "391/391 - 8s - 21ms/step - accuracy: 0.7863 - loss: 0.6335 - val_accuracy: 0.4919 - val_loss: 1.9620\n",
      "Epoch 7/25\n",
      "391/391 - 8s - 20ms/step - accuracy: 0.7741 - loss: 0.6641 - val_accuracy: 0.4901 - val_loss: 2.0399\n",
      "Epoch 8/25\n",
      "391/391 - 6s - 15ms/step - accuracy: 0.7602 - loss: 0.7083 - val_accuracy: 0.4835 - val_loss: 2.0686\n",
      "Epoch 9/25\n",
      "391/391 - 6s - 16ms/step - accuracy: 0.7609 - loss: 0.6953 - val_accuracy: 0.4759 - val_loss: 2.1329\n",
      "Epoch 10/25\n",
      "391/391 - 6s - 16ms/step - accuracy: 0.7544 - loss: 0.7110 - val_accuracy: 0.4712 - val_loss: 2.2615\n",
      "Epoch 11/25\n",
      "391/391 - 6s - 15ms/step - accuracy: 0.7523 - loss: 0.7165 - val_accuracy: 0.4755 - val_loss: 2.2041\n",
      "Epoch 12/25\n",
      "391/391 - 7s - 17ms/step - accuracy: 0.7693 - loss: 0.6733 - val_accuracy: 0.4823 - val_loss: 2.2135\n",
      "Epoch 13/25\n",
      "391/391 - 6s - 16ms/step - accuracy: 0.8061 - loss: 0.5757 - val_accuracy: 0.4908 - val_loss: 2.1577\n",
      "Epoch 14/25\n",
      "391/391 - 6s - 16ms/step - accuracy: 0.8377 - loss: 0.4956 - val_accuracy: 0.4816 - val_loss: 2.2741\n",
      "Epoch 15/25\n",
      "391/391 - 7s - 18ms/step - accuracy: 0.8654 - loss: 0.4302 - val_accuracy: 0.4893 - val_loss: 2.2933\n",
      "Epoch 16/25\n",
      "391/391 - 8s - 22ms/step - accuracy: 0.8861 - loss: 0.3765 - val_accuracy: 0.4922 - val_loss: 2.3202\n",
      "Epoch 17/25\n",
      "391/391 - 7s - 18ms/step - accuracy: 0.9048 - loss: 0.3281 - val_accuracy: 0.4951 - val_loss: 2.3686\n",
      "Epoch 18/25\n",
      "391/391 - 7s - 19ms/step - accuracy: 0.9182 - loss: 0.2913 - val_accuracy: 0.4925 - val_loss: 2.4104\n",
      "Epoch 19/25\n",
      "391/391 - 11s - 27ms/step - accuracy: 0.9300 - loss: 0.2603 - val_accuracy: 0.4904 - val_loss: 2.4558\n",
      "Epoch 20/25\n",
      "391/391 - 7s - 18ms/step - accuracy: 0.9388 - loss: 0.2368 - val_accuracy: 0.4927 - val_loss: 2.4624\n",
      "Epoch 21/25\n",
      "391/391 - 7s - 19ms/step - accuracy: 0.9445 - loss: 0.2182 - val_accuracy: 0.4956 - val_loss: 2.4446\n",
      "Epoch 22/25\n",
      "391/391 - 7s - 18ms/step - accuracy: 0.9483 - loss: 0.2046 - val_accuracy: 0.5009 - val_loss: 2.4134\n",
      "Epoch 23/25\n",
      "391/391 - 7s - 18ms/step - accuracy: 0.9497 - loss: 0.1957 - val_accuracy: 0.5066 - val_loss: 2.3835\n",
      "Epoch 24/25\n",
      "391/391 - 11s - 28ms/step - accuracy: 0.9516 - loss: 0.1891 - val_accuracy: 0.5126 - val_loss: 2.3621\n",
      "Epoch 25/25\n",
      "391/391 - 8s - 20ms/step - accuracy: 0.9518 - loss: 0.1856 - val_accuracy: 0.5170 - val_loss: 2.3441\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Review of results",
   "id": "a56f3d14978f03bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Epoch 25/25 391/391 - 8s - 20ms/step - accuracy: **0.9518** - loss: 0.1856 - val_accuracy: **0.5170** - val_loss: 2.3441\n",
    "\n",
    "1. Train score is 95.18% but validation score is 51.70% - model is overfitting !\n",
    "2. We can fix it by adding regularization techniques like Dropout, Data Augmentation, etc.\n",
    "3. Seems model with BatchNorm is better in terms of accuracy but slower in terms of training time."
   ],
   "id": "86272b42e54be05a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "62f86a5419aab256"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
