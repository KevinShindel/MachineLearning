{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T10:27:28.384611Z",
     "start_time": "2024-05-16T10:27:27.439914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ],
   "id": "a9d87a8a924dc2f5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Read and Write data using Pandas\n",
    "| Function          | Description           | Formats |\n",
    "|-------------------|-----------------------|---------|\n",
    "| pd.read_csv       | Read CSV file         | CSV     |\n",
    "| pd.read_excel     | Read Excel file       | XLSX    |\n",
    "| pd.read_sql       | Read SQL table        | SQL     |\n",
    "| pd.read_json      | Read JSON file        | JSON    |\n",
    "| pd.read_html      | Read HTML page        | HTML    |\n",
    "| pd.read_clipboard | Read clipboard        | CLIP    |\n",
    "| pd.read_fwf       | Read fixed-width file | FWF     |\n",
    "| pd.read_parquet   | Read parquet file     | PARQUET |\n",
    "| pd.to_csv         | Write CSV file        | CSV     |\n",
    "| pd.to_excel       | Write Excel file      | XLSX    |\n"
   ],
   "id": "5d0490ca6381c774"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Read and Write using Pandas",
   "id": "6431a03029d37a85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Read CSV file options\n",
    "\n",
    "| Option | Description | Example |\n",
    "|--------|-------------| ------- |\n",
    "| sep    | Delimiter to use | sep=';' |\n",
    "| header | Row number to use as column names | header=0 |\n",
    "| names  | List of column names | names=['a', 'b', 'c'] |\n",
    "| index_col | Column to use as index | index_col='date' |\n",
    "| usecols | Columns to read | usecols=['a', 'b'] |\n",
    "| dtype  | Data type for columns | dtype={'a': int, 'b': str} |\n",
    "| parse_dates | Parse dates | parse_dates=['date'] |\n",
    "| date_parser | Function to use for parsing dates | date_parser=parse_date |\n",
    "| na_values | Additional strings to recognize as NA | na_values=['missing'] |\n",
    "| thousands | Character to use as thousands separator | thousands='.' |\n",
    "| decimal | Character to use as decimal separator | decimal=',' |\n",
    "| skiprows | Number of rows to skip | skiprows=10 |\n",
    "| nrows | Number of rows to read | nrows=100 |\n",
    "| skipfooter | Number of rows to skip at end | skipfooter=10 |\n",
    "| encoding | Encoding to use | encoding='latin1' |\n",
    "| squeeze | Return series if possible | squeeze=True |\n",
    "| chunksize | Read file in chunks | chunksize=1000 |\n",
    "| iterator | Return TextFileReader object | iterator=True |\n",
    "| compression | Compression to use | compression='gzip' |\n",
    "| decimal | Character to use as decimal separator | decimal=',' |\n",
    "| quotechar | Quote character | quotechar='\"' |\n",
    "| quoting | Quoting style | quoting=csv.QUOTE_ALL |\n",
    "| escapechar | Character to use to escape | escapechar='\\\\' |\n",
    "| comment | Character to use as comment | comment='#' |\n",
    "| encoding | Encoding to use | encoding='latin1' |\n",
    "| dialect | Dialect to use | dialect='excel' |\n",
    "| error_bad_lines | Skip bad lines | error_bad_lines=False |\n",
    "| warn_bad_lines | Warn bad lines | warn_bad_lines=True |\n",
    "| low_memory | Use low memory mode | low_memory=True |\n",
    "| memory_map | Use memory map mode | memory_map=True |\n",
    "| float_precision | Floating point precision | float_precision='high' |\n"
   ],
   "id": "b13cf7e83439459b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CSV dialect Custom Class using\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "class MyDialect(csv.Dialect):\n",
    "    lineterminator = '\\n'\n",
    "    delimiter = ';'\n",
    "    quotechar = '\"'\n",
    "    quoting = csv.QUOTE_MINIMAL\n",
    "\n",
    "dialect = MyDialect()\n",
    "\n",
    "df = pd.read_csv('data.csv', dialect=dialect)\n",
    "```"
   ],
   "id": "e101c5827224ab42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Read specific Excel file options\n",
    "\n",
    "| Option | Description | Example |\n",
    "|--------|-------------| ------- |\n",
    "| sheet_name | Sheet to read | sheet_name='Sheet1' |\n",
    "\n"
   ],
   "id": "66ff4752416dbbeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Write CSV file options\n",
    "\n",
    "| Option          | Description                           | Example                |\n",
    "|-----------------|---------------------------------------|------------------------|\n",
    "| sep             | Delimiter to use                      | sep=';'                |\n",
    "| header          | Write column names                    | header=True            |\n",
    "| index           | Write row names                       | index=False            |\n",
    "| mode            | Write mode                            | mode='w'               |\n",
    "| encoding        | Encoding to use                       | encoding='latin1'      |\n",
    "| line_terminator | Line terminator                       | line_terminator='\\n'   |\n",
    "| quotechar       | Quote character                       | quotechar='\"'          |\n",
    "| quoting         | Quoting style                         | quoting=csv.QUOTE_ALL  |\n",
    "| escapechar      | Character to use to escape            | escapechar='\\\\'        |\n",
    "| decimal         | Character to use as decimal separator | decimal=','            |\n",
    "| float_format    | Floating point format                 | float_format='%.2f'    |\n",
    "| date_format     | Date format                           | date_format='%Y-%m-%d' |\n",
    "| doublequote     | Double quote                          | doublequote=True       |\n",
    "| na_rep          | NA representation                     | na_rep='missing'       |\n",
    "| columns         | Columns to write                      | columns=['a', 'b']     |"
   ],
   "id": "f5dd41524c902f40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Write Excel options   \n",
    "\n",
    "| Option          | Description                           | Example                          |\n",
    "|-----------------|---------------------------------------|----------------------------------|\n",
    "| sheet_name      | Sheet to write                        | sheet_name='Sheet1'              |\n",
    "| na_rep          | NA representation                     | na_rep='missing'                 |\n",
    "| float_format    | Floating point format                 | float_format='%.2f'              |\n",
    "| columns         | Columns to write                      | columns=['a', 'b']               |\n",
    "| header          | Write column names                    | header=True                      |\n",
    "| index           | Write row names                       | index=False                      |\n",
    "| startrow        | Starting row                          | startrow=2                       |\n",
    "| startcol        | Starting column                       | startcol=1                       |\n",
    "| engine          | Engine to use                         | engine='xlsxwriter'              |\n",
    "| merge_cells     | Merge cells                           | merge_cells=False                |\n",
    "| encoding        | Encoding to use                       | encoding='latin1'                |\n",
    "| inf_rep         | Infinite representation               | inf_rep='Inf'                    |\n",
    "| verbose         | Verbose output                        | verbose=True                     |\n",
    "| freeze_panes    | Freeze panes                          | freeze_panes=(1, 1)              |\n",
    "| storage_options | Storage options                       | storage_options={'key': 'value'} |\n",
    "| date_format     | Date format                           | date_format='YYYY-MM-DD'         |\n",
    "| decimal         | Character to use as decimal separator | decimal=','                      |\n",
    "| errors          | Error handling                        | errors='raise'                   |"
   ],
   "id": "1f852cdd943ecc11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JSON format operations\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSON format\n",
    "obj = \"\"\" \n",
    "{\"name\": \"Wes\",\n",
    " \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 38,\n",
    "               \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = json.loads(obj) # Convert JSON to Python dict\n",
    "asjson = json.dumps(result) # Convert Python dict to JSON\n",
    "\n",
    "# JSON to DataFrame\n",
    "siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])\n",
    "\n",
    "# JSON reading\n",
    "data = pd.read_json('data.json')"
   ],
   "id": "fdc455742783a1bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# HTML format operations\n",
    "\n",
    "tables = pd.read_html('data.html')\n",
    "failures = tables[0]\n",
    "\n",
    "close_timestamps = pd.to_datetime(failures.pop('Timestamp')) # Convert to datetime\n",
    "close_timestamps.dt.year.value_counts() # Count by year\n"
   ],
   "id": "8401d94e02ced5ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# XML reading using lxml.objectify\n",
    "\n",
    "from lxml import objectify\n",
    "\n",
    "path = 'data.xml'\n",
    "parsed = objectify.parse(open(path))\n",
    "root = parsed.getroot()\n",
    "\n",
    "data = []\n",
    "skip_fields = ['PARENT_SEQ', 'INDICATOR_SEQ', 'DESIRED_CHANGE', 'DECIMAL_PLACES']\n",
    "\n",
    "for el in root.INDICATOR: # Iterate over each XML element\n",
    "    el_data = {} # Create a dict\n",
    "    for child in el.getchildren(): # Iterate over each child element\n",
    "        if child.tag in skip_fields: # Skip some fields\n",
    "            continue\n",
    "        el_data[child.tag] = child.pyval # Add data to dict\n",
    "    data.append(el_data) # Append dict to list\n",
    "\n",
    "perf = pd.DataFrame(data) "
   ],
   "id": "231ba019f6260418"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Binary data formats\n",
    "\n",
    "frame = pd.read_csv('data.csv')\n",
    "\n",
    "frame.to_pickle('frame_pickle') # Write to pickle\n",
    "pd.read_pickle('frame_pickle') # Read from pickle"
   ],
   "id": "24d8f2599fbd5a30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T10:27:34.971646Z",
     "start_time": "2024-05-16T10:27:34.227954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# HDF5 format\n",
    "### HDF5 is optimized for reading and writing small data. But it is not optimized for writing large data.\n",
    "\n",
    "\n",
    "frame = pd.DataFrame({'a': np.random.randn(100)})\n",
    "store = pd.HDFStore('mydata.h5') # Create HDF5 file\n",
    "store['obj1'] = frame # Write to HDF5\n",
    "store['obj1_col'] = frame['a'] # Write to HDF5\n",
    "store['obj1'] # Read from HDF5\n",
    "store.put('obj2', frame, format='table') # Write to HDF5\n",
    "store.select('obj2', where=['index >= 10 and index <= 15']) # Read from HDF5\n",
    "store.close() # Close HDF5 file\n",
    "\n",
    "frame.to_hdf('mydata.h5', 'obj3', format='table') # Write to HDF5\n",
    "pd.read_hdf('mydata.h5', 'obj3', where=['index < 5']) # Read from HDF5"
   ],
   "id": "5428e198d6963390",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pytables'.  Use pip or conda to install pytables.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/Projects/MachineLearning/.venv/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001B[0m, in \u001B[0;36mimport_optional_dependency\u001B[0;34m(name, extra, errors, min_version)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 135\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1050\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1004\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tables'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# HDF5 format\u001B[39;00m\n\u001B[1;32m      3\u001B[0m frame \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m100\u001B[39m)})\n\u001B[0;32m----> 4\u001B[0m store \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHDFStore\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmydata.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m store[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobj1\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m frame\n\u001B[1;32m      6\u001B[0m store[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobj1_col\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m frame[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/Projects/MachineLearning/.venv/lib/python3.10/site-packages/pandas/io/pytables.py:566\u001B[0m, in \u001B[0;36mHDFStore.__init__\u001B[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001B[0m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat is not a defined argument for HDFStore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 566\u001B[0m tables \u001B[38;5;241m=\u001B[39m \u001B[43mimport_optional_dependency\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtables\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m complib \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m complib \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m tables\u001B[38;5;241m.\u001B[39mfilters\u001B[38;5;241m.\u001B[39mall_complibs:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    570\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcomplib only supports \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtables\u001B[38;5;241m.\u001B[39mfilters\u001B[38;5;241m.\u001B[39mall_complibs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m compression.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    571\u001B[0m     )\n",
      "File \u001B[0;32m~/Projects/MachineLearning/.venv/lib/python3.10/site-packages/pandas/compat/_optional.py:138\u001B[0m, in \u001B[0;36mimport_optional_dependency\u001B[0;34m(name, extra, errors, min_version)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 138\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: Missing optional dependency 'pytables'.  Use pip or conda to install pytables."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Interaction HTML via WEB API\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "resp = requests.get(url)\n",
    "\n",
    "data = resp.json()\n",
    "issues = pd.DataFrame(data, columns=['number', 'title', 'labels', 'state'])"
   ],
   "id": "f97c116a9c7ceb92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Interaction with DB\n",
    "\n",
    "import sqlite3\n",
    "import sqlalchemy as sqla\n",
    "\n",
    "query = \"\"\" # Query to create table\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    " c REAL,        d INTEGER\n",
    ");\"\"\"\n",
    "\n",
    "con = sqlite3.connect('mydata.sqlite') # Connect to SQLite\n",
    "con.execute(query) # Execute query\n",
    "con.commit() # Commit changes\n",
    "\n",
    "data = [('Atlanta', 'Georgia', 1.25, 6), # Data\n",
    "        ('Tallahassee', 'Florida', 2.6, 3),\n",
    "        ('Sacramento', 'California', 1.7, 5)]\n",
    "\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\" # Insert statement\n",
    "con.executemany(stmt, data) # Execute many\n",
    "con.commit() # Commit changes\n",
    "\n",
    "cursor = con.execute('select * from test') # Execute query\n",
    "rows = cursor.fetchall() # Fetch all rows\n",
    "cursor.description # Description\n",
    "\n",
    "pd.DataFrame(rows, columns=[x[0] for x in cursor.description]) # Create DataFrame\n",
    "\n",
    "# SQLAlchemy\n",
    "\n",
    "engine = sqla.create_engine('sqlite:///mydata.sqlite') # Create engine\n",
    "pd.read_sql('select * from test', engine) # Read from DB"
   ],
   "id": "b824bb59e4aa583"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
